{"categories":[{"title":"java","uri":"https://huayuye.github.io/blog/categories/java/"},{"title":"rpc","uri":"https://huayuye.github.io/blog/categories/rpc/"},{"title":"中间件","uri":"https://huayuye.github.io/blog/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"title":"工具","uri":"https://huayuye.github.io/blog/categories/%E5%B7%A5%E5%85%B7/"},{"title":"算法","uri":"https://huayuye.github.io/blog/categories/%E7%AE%97%E6%B3%95/"}],"posts":[{"content":"前言 由于公司的项目业务越来越繁杂，需要使用消息中间件的为服务进行一定的减压，所以就去了解些中间件，最后选了rabbitMQ。\n一、消息中间件适合使用的几个场景（这里列举的不是全部）： 1、系统间的解耦 比如某系统的数据需要同步到n个系统时，采取这种方式也是一种友好的实现，哪个系统需要数据就直接去订阅就行\n2、异步通知消息 比如邮件通知，短信通知等等\n3、高并发 如电商秒杀，促销活动等，可以适当的进行流量的控制，服务器的压力\n目前我知道的有Kafka,RabbitMQ,ActiveMQ,阿里的RocketMQ\n二、接下来我简单的学习下 RabbitMQ的用法 以Direct Exchange的方式举例：通过Routingkey精准的在Exchange找到相应的队列，另外还有 topic,fanout的方式\npom引入\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-amqp\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt;  1、基础配置\nimport org.springframework.amqp.core.*; import org.springframework.amqp.rabbit.connection.ConnectionFactory; import org.springframework.amqp.rabbit.core.RabbitAdmin; import org.springframework.amqp.rabbit.core.RabbitTemplate; import org.springframework.amqp.support.converter.Jackson2JsonMessageConverter; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; @Configuration public class RabbitMQConfig { public static final String testDirectExchange= \u0026quot;Test-DirectExchange\u0026quot;; public static final String testDirectExchangeQueue= \u0026quot;Test-Queue\u0026quot;; public static final String bindingDirectExchangeRoutingKey= \u0026quot;Test-RoutingKey\u0026quot;; @Bean public RabbitAdmin rabbitAdmin(ConnectionFactory connectionFactory){ RabbitAdmin rabbitAdmin = new RabbitAdmin(connectionFactory); rabbitAdmin.setAutoStartup(true); return rabbitAdmin; } @Bean public RabbitTemplate rabbitTemplate(ConnectionFactory connectionFactory){ RabbitTemplate rabbitTemplate = new RabbitTemplate(connectionFactory); /** * 设置RabbitTemplate的ConfirmCallback和ReturnCallback的时候注意： * 不论在哪里设置，只能设置一个（即只能设置一次或不配置：可在生产者类注入RabbitTemplate后设置，或我是在这里直接配置） * 否则会报如下异常 * Only one ConfirmCallback is supported by each RabbitTemplate */ rabbitTemplate.setMessageConverter(jackson2JsonMessageConverter()); rabbitTemplate.setConfirmCallback((correlationData, b, s)-\u0026gt;{ System.out.println(\u0026quot;correlationData = [\u0026quot; + correlationData + \u0026quot;], b = [\u0026quot; + b + \u0026quot;], s = [\u0026quot; + s + \u0026quot;]\u0026quot;); }); rabbitTemplate.setReturnCallback((message, i, s, s1, s2)-\u0026gt;{ System.out.println(\u0026quot;message = [\u0026quot; + message + \u0026quot;], i = [\u0026quot; + i + \u0026quot;], s = [\u0026quot; + s + \u0026quot;], s1 = [\u0026quot; + s1 + \u0026quot;], s2 = [\u0026quot; + s2 + \u0026quot;]\u0026quot;); }); return rabbitTemplate; } /** * 默认的json转换器，不支持实体对象的 * @return */ @Bean public Jackson2JsonMessageConverter jackson2JsonMessageConverter(){ Jackson2JsonMessageConverter jackson2JsonMessageConverter = new Jackson2JsonMessageConverter(); return jackson2JsonMessageConverter; } /** * 定义Exchange:这里定义为direct,另外的还有 fanout,topic * @return */ @Bean public DirectExchange testDirectExchange(){ return new DirectExchange(testDirectExchange); } /** * 定义队列 * @return */ @Bean public Queue testDirectExchangeQueue(){ return new Queue(testDirectExchangeQueue); } /** * 将队列绑定到Exchange,通过bindingKey来进行精确路由 * @return */ @Bean public Binding bindingDirectExchangeQueue(){ return BindingBuilder.bind(testDirectExchangeQueue()).to(testDirectExchange()).with(bindingDirectExchangeRoutingKey); } // @Bean // public IMQService mqService(RabbitTemplate rabbitTemplate){ // return new MQService(rabbitTemplate); // } }  2、发布消息\nimport org.springframework.amqp.rabbit.core.RabbitTemplate; import org.springframework.amqp.rabbit.support.CorrelationData; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Component; import java.util.UUID; @Component public class MQService implements IMQService { @Autowired private RabbitTemplate rabbitTemplate; public MQService(RabbitTemplate rabbitTemplate) { this.rabbitTemplate = rabbitTemplate; // this.rabbitTemplate.setConfirmCallback(tihs); // this.rabbitTemplate.setReturnCallback(tihs); } /** * 也可以直接在此类MQService 实现RabbitTemplate.ConfirmCallback和RabbitTemplate.ReturnCallback * 重写confirm和returnedMessage方法 * this.rabbitTemplate.setConfirmCallback(tihs); * this.rabbitTemplate.setReturnCallback(tihs); * * 切记：每个rabbitTemplate只能分别设置一次这两个回调，否则报异常 */ // RabbitTemplate.ConfirmCallback confirmCallback=new RabbitTemplate.ConfirmCallback() { // @Override // public void confirm(CorrelationData correlationData, boolean b, String s) { // System.out.println(\u0026quot;correlationData = [\u0026quot; + correlationData + \u0026quot;], b = [\u0026quot; + b + \u0026quot;], s = [\u0026quot; + s + \u0026quot;]\u0026quot;); // } // } ; // // RabbitTemplate.ReturnCallback returnCallback=new RabbitTemplate.ReturnCallback() { // @Override // public void returnedMessage(Message message, int i, String s, String s1, String s2) { // System.out.println(\u0026quot;message = [\u0026quot; + message + \u0026quot;], i = [\u0026quot; + i + \u0026quot;], s = [\u0026quot; + s + \u0026quot;], s1 = [\u0026quot; + s1 + \u0026quot;], s2 = [\u0026quot; + s2 + \u0026quot;]\u0026quot;); // } // }; // // public void sendMessage(MQMessage mqMessage) { //// this.rabbitTemplate.setConfirmCallback(confirmCallback); // this.rabbitTemplate.setReturnCallback(returnCallback); // CorrelationData correlationData = new CorrelationData(); // correlationData.setId(UUID.randomUUID().toString()); // this.rabbitTemplate.convertAndSend(RabbitMQConfig.testDirectExchange,RabbitMQConfig.bindingDirectExchangeRoutingKey,mqMessage,correlationData); // // } @Override public void sendExchangRoutingMessage(String exchange, String routingKey, MQMessage mqMessage) { CorrelationData correlationData = new CorrelationData(); correlationData.setId(UUID.randomUUID().toString()); this.rabbitTemplate.convertAndSend(exchange,routingKey,mqMessage,correlationData); } @Override public void sendRoutingMessage(String routingKey, MQMessage mqMessage) { CorrelationData correlationData = new CorrelationData(); correlationData.setId(UUID.randomUUID().toString()); this.rabbitTemplate.convertAndSend (routingKey,mqMessage,correlationData); } }  3、消费者(springboot监听器的方式)\nimport org.springframework.amqp.rabbit.annotation.RabbitListener; import org.springframework.stereotype.Component; /** * 队列监听器 * 这里我直接在一个类里面监听了多个队列的形式 * 也可以直接在类上面加上 @RabbitListener结合 在方法上加上@RabbitHandler处理收到的信息 */ @Component public class MessageListener { @RabbitListener(queues = RabbitMQConfig.testDirectExchangeQueue) public void testQueueMessage(TestMQMessage mqMessage){ System.out.println(\u0026quot;Test-Queue Receive Msg = [\u0026quot; + mqMessage.getMsg() + \u0026quot;]\u0026quot;); } // @RabbitListener(queues = RabbitMQConfig.testTopicExchangeQueue) // public void testTopicQueueMessage(TestMQMessage mqMessage){ // System.out.println(\u0026quot;Test-Topic-Queue Receive Msg = [\u0026quot; + mqMessage.getMsg() + \u0026quot;]\u0026quot;); // } }  ","id":0,"section":"posts","summary":"前言 由于公司的项目业务越来越繁杂，需要使用消息中间件的为服务进行一定的减压，所以就去了解些中间件，最后选了rabbitMQ。 一、消息中间件适","tags":["mq"],"title":"Springboot Rabbitmq","uri":"https://huayuye.github.io/blog/2021/12/springboot-rabbitmq/","year":"2021"},{"content":"之前项目中只是单纯的使用其中的一种方式，这里介绍下其他的方式\n一、生产者 1、创建服务连接\nprivate static ConnectionFactory connectionFactory = null; static { connectionFactory = new ConnectionFactory(); connectionFactory.setHost(\u0026quot;192.168.43.120\u0026quot;); connectionFactory.setPort(5672); connectionFactory.setUsername(\u0026quot;root\u0026quot;); connectionFactory.setPassword(\u0026quot;root\u0026quot;); // connectionFactory.setVirtualHost(\u0026quot;/\u0026quot;); }  2、定义队列\npublic static void declareExchange(String exchangeType,String testQueue, String testExchange, String testRoutingkey) { try { Connection connection = connectionFactory.newConnection(); Channel channel = connection.createChannel(); channel.exchangeDeclare(testExchange,exchangeType,true); channel.queueDeclare(testQueue,false,false,false,null); channel.queueBind(testQueue, testExchange, testRoutingkey); System.out.println(\u0026quot;declareExchange,exchangeType = [\u0026quot; + exchangeType + \u0026quot;], testQueue = [\u0026quot; + testQueue + \u0026quot;], testExchange = [\u0026quot; + testExchange + \u0026quot;], testRoutingkey = [\u0026quot; + testRoutingkey + \u0026quot;]\u0026quot;); } catch (IOException e) { e.printStackTrace(); } catch (TimeoutException e) { e.printStackTrace(); } } public static void declareQueue(String testQueue) { try { Connection connection = connectionFactory.newConnection(); Channel channel = connection.createChannel(); channel.queueDeclare(testQueue,false,false,false,null); System.out.println(\u0026quot;declareQueue,testQueue = [\u0026quot; + testQueue + \u0026quot;]\u0026quot;); } catch (IOException e) { e.printStackTrace(); } catch (TimeoutException e) { e.printStackTrace(); } }  3、发布消息\npublic static void publishExchange(String msg, String testExchange, String testRoutingkey) { try { Connection connection = connectionFactory.newConnection(); Channel channel = connection.createChannel(); channel.basicPublish( testExchange, testRoutingkey, null, msg.getBytes() ); System.out.println(\u0026quot;publishExchange,msg = [\u0026quot; + msg + \u0026quot;], testQueue = [\u0026quot; + MQConfig.queue_test + \u0026quot;], testExchange = [\u0026quot; + testExchange + \u0026quot;], testRoutingkey = [\u0026quot; + testRoutingkey + \u0026quot;]\u0026quot;); } catch (IOException e) { e.printStackTrace(); } catch (TimeoutException e) { e.printStackTrace(); } } public static void publishToQueue(String msg, String testQueue) { try { Connection connection = connectionFactory.newConnection(); Channel channel = connection.createChannel(); channel.basicPublish( \u0026quot;\u0026quot;, testQueue, null, msg.getBytes() ); System.out.println(\u0026quot;publishToQueuen,msg = [\u0026quot; + msg + \u0026quot;], testQueue = [\u0026quot; + testQueue + \u0026quot;]\u0026quot;); } catch (IOException e) { e.printStackTrace(); } catch (TimeoutException e) { e.printStackTrace(); } }  二、消费者 public static void comsumer(String name,String testQueue) { try { Connection connection = connectionFactory.newConnection(); Channel channel = connection.createChannel(); while (true){ //自动确认回复 channel.basicConsume(testQueue,true,new DefaultConsumer(channel){ @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException { dowork(name+\u0026quot;-\u0026quot;+consumerTag+\u0026quot;-comsumer: \u0026quot;+new String(body)); } }); } } catch (IOException e) { e.printStackTrace(); } catch (TimeoutException e) { e.printStackTrace(); } } //具体的业务实现 public static void dowork(String msg){ System.out.println(\u0026quot;msg = [\u0026quot; + msg + \u0026quot;]\u0026quot;); }  三、广播，主题，路由的体验 1、广播\n/** * 广播 * 不会校验RoutingKey * 直接将消息发送到指定交换机的所有queue中 */ private static void testFaoutExchange() { MQProductor.declareExchange(MQConfig.type_exchange_faout,MQConfig.fanout_exchange_queue1_test,MQConfig.fanout_exchange_test,MQConfig.fanout_routingkey1_test); MQProductor.declareExchange(MQConfig.type_exchange_faout,MQConfig.fanout_exchange_queue2_test,MQConfig.fanout_exchange_test,MQConfig.fanout_routingkey2_test); for(int i=0;i\u0026lt;=100000;i++){ if(i%2==0){ MQProductor.publishExchange(\u0026quot;faout-TestProductor[1]-\u0026quot;+i,MQConfig.fanout_exchange_test,MQConfig.fanout_routingkey1_test); }else { MQProductor.publishExchange(\u0026quot;faout-TestProductor[2]-\u0026quot;+i,MQConfig.fanout_exchange_test,MQConfig.fanout_routingkey2_test); } try { Thread.sleep(3000); } catch (InterruptedException e) { e.printStackTrace(); } } }  2、路由 精准匹配\n/** * routingkey路由 精准匹配 */ private static void testDirectExchange() { MQProductor.declareExchange(MQConfig.type_exchange_direct,MQConfig.direct_queue_test,MQConfig.direct_exchange_test,MQConfig.direct_routingkey_test); MQProductor.declareExchange(MQConfig.type_exchange_direct,MQConfig.direct_queue2_test,MQConfig.direct_exchange_test,MQConfig.direct_routingkey2_test); for(int i=0;i\u0026lt;=100000;i++){ if(i%2==0){ MQProductor.publishExchange(\u0026quot;Direct-TestProductor[1]-\u0026quot;+i,MQConfig.direct_exchange_test,MQConfig.direct_routingkey_test); }else { MQProductor.publishExchange(\u0026quot;Direct-TestProductor[2]-\u0026quot;+i,MQConfig.direct_exchange_test,MQConfig.direct_routingkey2_test); } try { Thread.sleep(3000); } catch (InterruptedException e) { e.printStackTrace(); } } }  3、主题模式\n/** * 主题模式 * 主要是模糊匹配 * 当生产者推送消息时，会在指定的交换机中通过Publish时指定的RoutingKey与已经绑定好queue的BindingKey进行模糊匹配， * 当匹配到所有符合BindingKey，就会将此消息推送到相应BindingKey绑定的queue中 * BindingKey规则： * .# 表示匹配0个或多个. (如 #.topic 能匹配的routingKey(topci, xx.topic,xx.xx.topic等；topic.# 也类似)） * .* 表示.个数要严格匹配（如*.topic 能匹配的routingKey(只能匹配 xx.topic，匹配不到 xx.xx.topic；topic.* 也类似)） */ private static void testTopic() { MQProductor.declareExchange(MQConfig.type_exchange_topic,MQConfig.topic_queue1_test,MQConfig.topic_exchange_test,MQConfig.topic_routingkey1_test); MQProductor.declareExchange(MQConfig.type_exchange_topic,MQConfig.topic_queue2_test,MQConfig.topic_exchange_test,MQConfig.topic_routingkey2_test); MQProductor.declareExchange(MQConfig.type_exchange_topic,MQConfig.topic_queue3_test,MQConfig.topic_exchange_test,MQConfig.topic_routingkey3_test); MQProductor.declareExchange(MQConfig.type_exchange_topic,MQConfig.topic_queue4_test,MQConfig.topic_exchange_test,MQConfig.topic_routingkey4_test); MQProductor.declareExchange(MQConfig.type_exchange_topic,MQConfig.topic_queue5_test,MQConfig.topic_exchange_test,MQConfig.topic_routingkey5_test); MQProductor.declareExchange(MQConfig.type_exchange_topic,MQConfig.topic_queue6_test,MQConfig.topic_exchange_test,MQConfig.topic_routingkey6_test); for(int j=0;j\u0026lt;=100000;j++){ if(j%3==0){ MQProductor.publishExchange(\u0026quot;Topic-TestProductor[r1/r2]-\u0026quot;+j,MQConfig.topic_exchange_test,MQConfig.topic_routingkey_test+\u0026quot;.2\u0026quot;); }else if(j%3==1){ MQProductor.publishExchange(\u0026quot;Topic-Test r3/r4-TestProductor[r4]-\u0026quot;+j,MQConfig.topic_exchange_test,MQConfig.topic_routingkey_test); }else if(j%3==2){ MQProductor.publishExchange(\u0026quot;Topic-Test r3/r4-TestProductor[r5]-\u0026quot;+j,MQConfig.topic_exchange_test,\u0026quot;5.\u0026quot;+MQConfig.topic_routingkey_test+\u0026quot;.5\u0026quot;+\u0026quot;.5\u0026quot;); } try { Thread.sleep(3000); } catch (InterruptedException e) { e.printStackTrace(); } } }  4、多消费者监听同一队列（若是要求每个消息只允许被消费一次话，必须自己实现一个类似锁机制的功能来控制，如果这个消息被消费过，下一个消费者就不能再消费了）\n/** * 多个消费者消费一个queue */ public static void multiComsumerToqueue(){ new Thread(()-\u0026gt;{ MQComsumer.comsumer(\u0026quot;multi-Comsumer1\u0026quot;,MQConfig.queue_test); }).start(); new Thread(()-\u0026gt;{ MQComsumer.comsumer(\u0026quot;multi-Comsumer2\u0026quot;,MQConfig.queue_test); }).start(); }  ","id":1,"section":"posts","summary":"之前项目中只是单纯的使用其中的一种方式，这里介绍下其他的方式 一、生产者 1、创建服务连接 private static ConnectionFactory connectionFactory = null; static { connectionFactory = new ConnectionFactory(); connectionFactory.setHost(\u0026quot;192.168.43.120\u0026quot;); connectionFactory.setPort(5672); connectionFactory.setUsername(\u0026quot;root\u0026quot;); connectionFactory.setPassword(\u0026quot;root\u0026quot;); // connectionFactory.setVirtualHost(\u0026quot;/\u0026quot;); } 2、定义队列 public static","tags":["mq"],"title":"Java Rabbitmq","uri":"https://huayuye.github.io/blog/2021/12/java-rabbitmq/","year":"2021"},{"content":"RabbitMQ基于erlang语言： 是一种支持高并发的语言\nRabbitMQ的工作模式 1. simple简单模式 （1）消息产生者将消息放入队列\n（2）消息的消费者(consumer) 监听(while) 消息队列,如果队列中有消息,就消费掉,消息被拿走后,自动从队列中删除(隐患 消息可能没有被消费者正确处理,已经从队列中消失了,造成消息的丢失)\n（3）应用场景:聊天(中间有一个过度的服务器：p端,c端)\n2. work工作模式(资源的竞争) （1） 消息产生者将消息放入队列消费者可以有多个,消费者1,消费者2,同时监听同一个队列\n（2） 消息被消费C1 C2共同争抢当前的消息队列内容,谁先拿到谁负责消费消息(隐患,高并发情况下,默认会产生某一个消息被多个消费者共同使用,可以设置一个开关(syncronize,与同步锁的性能不一样) 保证一条消息只能被一个消费者使用)\n（3） 应用场景:红包;大项目中的资源调度(任务分配系统不需知道哪一个任务执行系统在空闲,直接将任务扔到消息队列中,空闲的系统自动争抢)\n3. publish/subscribe发布订阅(Exchange 共享资源) (1) X(Exchange)代表交换机rabbitMQ内部组件,消息产生者将消息放入交换机,交换机发布订阅把消息发送到所有消息队列中,对应消息队列的消费者拿到消息进行消费\n(2) 相关场景:邮件群发,群聊天,广播(广告)\n4. routing路由模式 （1）RabbitMQ中通过Binding（binding key）将Exchange与Queue关联起来，这样RabbitMQ就知道如何正确地将消息路由到指定的Queue\n（2）生产者在将消息发送给Exchange的时候，一般会指定一个routing key，来指定这个消息的路由规则，当binding key与routing key相匹配时，消息将会被路由到对应的Queue中。\n（3）在Exchange Type与binding key固定的情况下（在正常使用时一般这些内容都是固定配置好的），我们的生产者就可以在发送消息给Exchange时，通过指定routing key来决定消息流向哪里。\n（4）Exchange Type 常用分为\nfanout : 会把所有发送到该Exchange的消息路由到所有与它绑定的Queue中\ndirect : 把消息路由到那些binding key与routing key完全匹配的Queue中\ntopic:下文详细讲\nheaders: 该类型的Exchange没有用到过\n（5）业务场景:\nerror 通知; EXCEPTION; 错误通知的功能; 传统意义的错误通知; 客户通知;\n利用key路由,可以将程序中的错误封装成消息传入到消息队列中,开发者可以自定义消费者,实时接收错误;\n5. topic 主题模式(路由模式的一种) binding key中可以存在两种特殊字符*与#，用于做模糊匹配，其中“*”用于匹配一个单词，“#”用于匹配多个单词（可以是零个）\n(1) 星号井号代表通配符 (2) 星号代表多个单词,井号代表一个单词 (3) 路由功能添加模糊匹配 (4) 消息产生者产生消息,把消息交给交换机 (5) 交换机根据key的规则模糊匹配到对应的队列,由队列的监听消费者接收消息消费\n6.RPC RabbitMQ中实现RPC的机制是：\n客户端发送请求（消息）时，在消息的属性（MessageProperties，在AMQP协议中定义了14中properties，这些属性会随着消息一起发送）中设置两个值replyTo（一个Queue名称，用于告诉服务器处理完成后将通知我的消息发送到这个Queue中）和correlationId（此次请求的标识号，服务器处理完成后需要将此属性返还，客户端将根据这个id了解哪条请求被成功执行了或执行失败） 服务器端收到消息并处理 服务器端处理完消息后，将生成一条应答消息到replyTo指定的Queue，同时带上correlationId属性 客户端之前已订阅replyTo指定的Queue，从中收到服务器的应答消息后，根据其中的correlationId属性分析哪条请求被执行了，根据执行结果进行后续业务处理\n原文\n","id":2,"section":"posts","summary":"RabbitMQ基于erlang语言： 是一种支持高并发的语言 RabbitMQ的工作模式 1. simple简单模式 （1）消息产生者将消息放入队列 （","tags":["mq"],"title":"Rabbitmq Work Model","uri":"https://huayuye.github.io/blog/2021/12/rabbitmq-work-model/","year":"2021"},{"content":"一. 安装 1、gcc 安装\n安装 nginx 需要先将官网下载的源码进行编译，编译依赖 gcc 环境，如果没有 gcc 环境，则需要安装：\nyum install gcc-c++  2. PCRE pcre-devel 安装\nPCRE(Perl Compatible Regular Expressions) 是一个Perl库，包括 perl 兼容的正则表达式库。nginx 的 http 模块使用 pcre 来解析正则表达式，所以需要在 linux 上安装 pcre 库，pcre-devel 是使用 pcre 开发的一个二次开发库。nginx也需要此库。命令：\nyum install -y pcre pcre-devel  3. zlib 安装\nzlib 库提供了很多种压缩和解压缩的方式， nginx 使用 zlib 对 http 包的内容进行 gzip ，所以需要在 Centos 上安装 zlib 库。\nyum install -y zlib zlib-devel  4. OpenSSL 安装\nOpenSSL 是一个强大的安全套接字层密码库，囊括主要的密码算法、常用的密钥和证书封装管理功能及 SSL 协议，并提供丰富的应用程序供测试或其它目的使用。 nginx 不仅支持 http 协议，还支持 https（即在ssl协议上传输http），所以需要在 Centos 安装 OpenSSL 库。\nyum install -y openssl openssl-devel  6、 直接下载.tar.gz安装包，地址： https://nginx.org/en/download.html\nwget -c https://nginx.org/download/nginx-1.10.3.tar.gz\n7、解压 tar.gz,进入nginx-1.10.3\ncd nginx-1.10.3  7、开始安装，我使用默认配置方式安装（此方式会安装在：/usr/local/nginx）\n（1）.使用默认配置\n./configure  （2）.自定义配置（不推荐）\n./configure \\ --prefix=/usr/local/nginx \\ --conf-path=/usr/local/nginx/conf/nginx.conf \\ --pid-path=/usr/local/nginx/conf/nginx.pid \\ --lock-path=/var/lock/nginx.lock \\ --error-log-path=/var/log/nginx/error.log \\ --http-log-path=/var/log/nginx/access.log \\ --with-http_gzip_static_module \\ --http-client-body-temp-path=/var/temp/nginx/client \\ --http-proxy-temp-path=/var/temp/nginx/proxy \\ --http-fastcgi-temp-path=/var/temp/nginx/fastcgi \\ --http-uwsgi-temp-path=/var/temp/nginx/uwsgi \\ --http-scgi-temp-path=/var/temp/nginx/scgi  注：使用自定义配置安装时：将临时文件目录指定为/var/temp/nginx，需要在/var下创建temp及nginx目录\n（3）、编译安装\n在nginx-1.10.3 下执行：\nmake make install  （4）、启动、停止nginx\ncd /usr/local/nginx/sbin/ ./nginx ./nginx -s stop ./nginx -s quit ./nginx -s reload  8、指定 配置文件启动\n./sbin/nginx -c /usr/local/nginx/conf/nginx.conf  二、已安装了的nginx，添加模块 1、切换到源码包：\ncd /usr/local/src/nginx-1.10.3  2、查看nginx原有的模块\n/usr/local/nginx/sbin/nginx -V  3、在configure arguments:后面显示的原有的configure参数如下：\n--prefix=/usr/local/nginx --with-http_stub_status_module  4、新配置信息就应该这样写（源码包路径下）：\n./configure --prefix=/usr/local/nginx --with-http_stub_status_module --with-http_ssl_module  运行上面的命令即可，等配置完\n5、配置完成后，运行命令（源码包路径下）\nmake  注意：这里不要进行make install，否则就是覆盖安装\n6、备份原有已安装好的nginx（源码包路径下）\ncp /usr/local/nginx/sbin/nginx /usr/local/nginx/sbin/nginx.bak  7、将刚刚编译好的nginx覆盖掉原有的nginx（源码包路径下）（这个时候nginx要停止状态）\ncp ./objs/nginx /usr/local/nginx/sbin/  8、启动nginx，仍可以通过命令查看是否已经加入成功\n/usr/local/nginx/sbin/nginx -V  ","id":3,"section":"posts","summary":"一. 安装 1、gcc 安装 安装 nginx 需要先将官网下载的源码进行编译，编译依赖 gcc 环境，如果没有 gcc 环境，则需要安装： yum install gcc-c++ 2. PCRE pcre-devel 安装 PCRE(Perl Compatible Regular Expressions) 是一个Per","tags":["nginx"],"title":"Centos安装Nginx","uri":"https://huayuye.github.io/blog/2021/12/centos-nginx/","year":"2021"},{"content":"前言 这里是基于JDK8版本探究的。 JDK7及之后有所变化: 将String常量池 从 Perm 区移动到了 Java Heap区,String的intern 方法时，如果存在堆中的对象，会直接保存对象的引用，而不会重新创建对象\n1、 String常量池问题 String str1 = \u0026quot;abc123\u0026quot;; String str2 = \u0026quot;abc\u0026quot;; String str3 = \u0026quot;abc\u0026quot; + \u0026quot;123\u0026quot;; String str4 = str2 + \u0026quot;123\u0026quot;; final String str5 = \u0026quot;ab\u0026quot;; String str6 = str5 + \u0026quot;c123\u0026quot;; System.out.println(\u0026quot;str1 == str3 is \u0026quot;+(str1 == str3)) System.out.println(\u0026quot;str1 == str4 is \u0026quot;+(str1 == str4)); System.out.println(\\\u0026quot;str1 == str6 is \\\u0026quot;+(str1 == str6)) System.out.println(\u0026quot;str4 == str6 is \u0026quot;+(str4 == str6));  str4: 因为str2没有被final修饰，存在字符串引用str2，在编译时期未确定的，在运行时，才动态将str2+\u0026ldquo;123\u0026quot;连接后的新地址赋给str4，先是放到堆内存，字符串常量池是没有的，str4是对它的引用。\nstr3: 因为\u0026quot;abc\u0026rdquo;,\u0026ldquo;123\u0026quot;都是常量，在常量池里面，编译时\u0026quot;abc\u0026rdquo; + \u0026ldquo;123\u0026quot;连接后值在常量池中,并且\u0026quot;abc123\u0026quot;已在常量池中存在，最后将连接后地址赋给str3\nstr6: 因为str5是被final修饰了，因此是直接在常量池生成，str5+\u0026ldquo;c123\u0026quot;值在常量池中。 因此str1与str3、str1与str6返回true,而str1和str4返回false\n总结：\n1)当字符串使用\u0026rdquo;+\u0026ldquo;时，首先回去字符串常量池中查找是否已存在，存在就直接引用\n2)只有当都是字符串常量使用\u0026rdquo;+\u0026ldquo;连接后，才会直接在常量池中生成。\n3)存在引用连接时，就只会先在堆内存中。\n2 、String的intern()方法 String str8 = \u0026quot;xyz567\u0026quot;; String str9 = \u0026quot;xyz\u0026quot;; String str10 = \u0026quot;567\u0026quot;; String str11 = new String(\u0026quot;xyz567\u0026quot;); String str12 = str11.intern(); System.out.println(\u0026quot;str8 == str11 is \u0026quot;+(str8 == str11)); System.out.println(\u0026quot;str8 == str12 is \u0026quot;+(str8 == str12));  当前调用intern()时，str11会到常量池中查询，查询完后就返回它的引用，将引用赋给str12\nString str13 = new String(\u0026quot;a\u0026quot;)+new String(\u0026quot;a\u0026quot;); str13.intern(); String str14 = \u0026quot;aa\u0026quot;; System.out.println(\u0026quot;str13 == str14 is \u0026quot;+(str13 == str14));  首先在head中创建两个对象(常量池a,堆内存str13的引用对象)，而对象在\u0026rdquo;+\u0026ldquo;之后的\u0026quot;aa\u0026quot;的地址引用返回给str13，但是这时常量池中是没有\u0026quot;aa\u0026quot;的，调用intern()后，就会往常量池中放\u0026quot;aa\u0026rdquo;。\n由于JDK7后，常量池并没有在perm pace了，而是直接在head中分一块为String pool，把堆中对\u0026quot;aa\u0026quot;的引用放一份到常量池。\nstr13.intern(),返回对\u0026quot;aa\u0026quot;的引用，而这时再直接定义str14对常量\u0026quot;aa\u0026quot;的引用，其指向的也是str13的引用地址，因此str13 == str14返回true。\nString str13 = new String(\u0026quot;a\u0026quot;)+new String(\u0026quot;a\u0026quot;); String str14 = \u0026quot;aa\u0026quot;; str13.intern(); System.out.println(\u0026quot;str13 == str14 is \u0026quot;+(str13 == str14));  首先在head中创建两个对象(常量池a,堆内存str13的引用对象)，而对象在\u0026rdquo;+\u0026ldquo;之后的\u0026quot;aa\u0026quot;的地址引用返回给str13，这时常量池中是没有\u0026quot;aa\u0026quot;的。\n此时再直接定义str14,对常量\u0026quot;aa\u0026quot;引用时，直接在常量池中创建的新对象。\n再调用str13.intern()时，发现常量池中已经存在\u0026quot;aa\u0026rdquo;,就不会再将引用存一份到常量池中。\n因此str13的引用与str14的引用地址是不同的， str13 == str14返回false。\nConnected to the target VM, address: 127.0.0.1:64387, transport: socket str1 == str3 is true str1 == str4 is false str1 == str6 is true str4 == str6 is false str8 == str11 is false str8 == str12 is true str13 == str14 is true str13 == str14 is false Disconnected from the target VM, address: 127.0.0.1:64387, transport: socket  ","id":4,"section":"posts","summary":"前言 这里是基于JDK8版本探究的。 JDK7及之后有所变化: 将String常量池 从 Perm 区移动到了 Java Heap区,String的intern 方法时，","tags":["java"],"title":"String Pool","uri":"https://huayuye.github.io/blog/2021/12/string-pool/","year":"2021"},{"content":"建议且规定 起码三台或以上奇数台机器。\n一、服务器三台 ： server1(x.x.x.221)\nserver2(x.x.x.222)\nserver3(x.x.x.223)\n1、每台服务器上均要放 zookeeper 2、将zookeeper-3.4.12.tar.gz解压到自定义文件夹 3、进入到 conf ,将 zoo_sample.cfg 复制一份并命名为 zoo.cfg\n二、zk的配置 1、server1 的 zoo.cfg 配置\n\t# The number of milliseconds of each tick tickTime=2000 # The number of ticks that the initial # synchronization phase can take initLimit=10 # The number of ticks that can pass between # sending a request and getting an acknowledgement syncLimit=5 # the directory where the snapshot is stored. # do not use /tmp for storage, /tmp here is just # example sakes. #dataDir=/tmp/zookeeper #数据存放路径 dataDir=/data/zk/data dataLogDir=/data/zk/logs # the port at which the clients will connect #端口 clientPort=2181 # the maximum number of client connections. # increase this if you need to handle more clients #maxClientCnxns=60 # # Be sure to read the maintenance section of the # administrator guide before turning on autopurge. # # [http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance](http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance) # # The number of snapshots to retain in dataDir #autopurge.snapRetainCount=3 # Purge task interval in hours # Set to \\\u0026quot;0\\\u0026quot; to disable auto purge feature #autopurge.purgeInterval=1 #这里的集群设置注意：本机上的server的端口不能与本机上的clientPort一样，否则会端口被占用 #server.A=B:C:D A表示几号服务器（整数：1，2，3），B表示ip, C表示信息交互端口（注意这个端口并不是zk服务器上的端口clientPort ，），D表示后期参与选举leader的端口 server.1=x.x.x.221:2182:3181 server.2=x.x.x.222:2182:3181 server.3=x.x.x.223:2182:3181  2、server2、server3的zoo.cfg配置和server1的一样（只改server.2，3的ip，其他什么都不用改）\n3、在每台zk服务器上的zoo.cfg文件里面配置的dataDir路径下创建一个myid文件,每台对应的myid里面的内容为 server.A=B:C:D中的A的值 例如在server1下的/data/zk/data 创建文件myid，里面内容为1\n注意：以上配置涉及的端口都记得相应的添加到防火墙\n三、启动zk 1、进入到bin目录下 (1)启动 ./zkServer.sh start (2)查看状态 ./zkServer.sh status (3)停止服务 ./zkServer.sh stop\n启动成功后，即可使用zk了\n四、遇到的问题 1、刚开始以为 server.A=B:C:D 中的 C 就是每台服务器的cfg文件中配置的clientPort，最后发现不是这样，不理解配置走了一点弯路 解决： 集群间的信息交互端口（C）必须配成与对应zk的端口不同的端口。\n五、springboot+dubbo的zk集群配置实例 一、提供者与消费者集群\n1、提供者集群（dubbo 的配置一致，服务名称也要一样）\n（1）、提供者1\n\tdubbo: registry: address: x.x.x.221:2181,x.x.x.222:2181 protocol: zookeeper application: name: basic-edu-service-provider id: basic-edu-service-provider scan: basePackages: com.lifefun.edu.provider provider: timeout: 6000 protocol: port: 20882  （2）、提供者2\n\tdubbo: registry: address: x.x.x.221:2181,x.x.x.222:2181 protocol: zookeeper application: name: basic-edu-service-provider id: basic-edu-service-provider scan: basePackages: com.lifefun.edu.provider provider: timeout: 6000 protocol: port: 20882  2、消费者集群(api需要共用的 一样，服务名称要不一样)\n（1）、消费者 1\n\tdubbo: registry: address: x.x.x.221:2181,x.x.x.222:2181 protocol: zookeeper application: name: basic-edu-service-comsumer id: basic-edu-service-comsumer scan: basePackages: com.lifefun.edu.api provider: timeout: 6000 protocol: port: 20882  （2）、消费者 2\n\tdubbo: registry: address: x.x.x.221:2181,x.x.x.222:2181 protocol: zookeeper application: name: basic-edu-service-comsumer2 id: basic-edu-service-comsumer scan: basePackages: com.lifefun.edu.api provider: timeout: 6000 protocol: port: 20882  ","id":5,"section":"posts","summary":"建议且规定 起码三台或以上奇数台机器。 一、服务器三台 ： server1(x.x.x.221) server2(x.x.x.222) server3(x.x.x.223) 1、每台服务器上均要放 zookeeper 2、将zookeeper-3.4.12.tar.gz解压到","tags":["dubbo"],"title":"Springboot Dubbo Cluster","uri":"https://huayuye.github.io/blog/2021/12/springboot-dubbo-cluster/","year":"2021"},{"content":"一、下载并安装zookeeper dubbo的注册中可以选redis，zookeeper等，这里使用zookeeper作为dubbo的注册中心\n1、下载 https://mirrors.cnnic.cn/apache/zookeeper/\n2、安装 （1）将下载的压缩包根据自己的喜好解压到指定目录（/home/bdmac/software/zk）\n（2）进入解压目录，在conf下将zoo_sample.cfg复制一份更名为zoo.cfg,修改里面配置，我的配置如下\n tickTime=2000 # The number of ticks that the initial # synchronization phase can take initLimit=10 # The number of ticks that can pass between # sending a request and getting an acknowledgement syncLimit=5 # the directory where the snapshot is stored. # do not use /tmp for storage, /tmp here is just # example sakes. #数据存储处 dataDir=/home/bdmac/software/zk/data #日志存储 dataLogDir=/home/bdmac/software/zk/logs #the port at which the clients will connect #端口 clientPort=2181  3、启动zk (1)进入bin目录，执行zkServer.sh命令,默认会使用刚配置的zoo.cfg\n./zkServer.sh start  (2)zk的启动相关命令\n./zkServer.sh start ./zkServer.sh stop ./zkServer.sh restart ./zkServer.sh status  二、安装 dubbo-admin 用于查看服务注册、订阅、调用等情况 1、gitgub上下载，2.6版本之后，dubbo-admin就没有了。而是放在了这里面 https://github.com/apache/incubator-dubbo-ops/tree/master\n2、整个项目下载下来后，进入到dubbo-admin目录下,执行以下命令，打包 mvn package -Dmaven.skip.test=true 接下来进入到target下找到相应的war，直接丢进去tomcat，启动tomcat即可\n三、项目中pom及yml的配置 项目结构 dubbo-api dubbo-provider dubbo-ccomsumers三个模块， api分别给provider和comsumer引用\n1、引入的pom\n\t\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.spring.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;dubbo-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.0.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.101tec\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;zkclient\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.9\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;  2、项目示例请前往： [https://github.com/huayuye/springboot-dubbo-test] (https://github.com/huayuye/springboot-dubbo-test)\n四、碰到的问题 1、项目中接口调用也直接报空指针异常: 原因：是@Refrence 的IService 为null，而为null的原因，是因为注册中心没有找到相应服务\n2、针对我的解决： 在提供者和消费者启动类上加上这个注解扫描基础包： @EnableDubbo(scanBasePackages = {\u0026quot;com.bingdeng.dubbo.provider\u0026quot;}) @EnableDubbo(scanBasePackages={\u0026quot;com.bingdeng.dubbo.comsumer\u0026quot;})\n","id":6,"section":"posts","summary":"一、下载并安装zookeeper dubbo的注册中可以选redis，zookeeper等，这里使用zookeeper作为dubbo的注册中心","tags":["dubbo"],"title":"Springboot Dubbo","uri":"https://huayuye.github.io/blog/2021/12/springboot-dubbo/","year":"2021"},{"content":"1、初始化一个 RestHighLevelClien\nRestHighLevelClient client = new RestHighLevelClient( RestClient.builder( new HttpHost(\u0026quot;localhost\u0026quot;, 9200, \u0026quot;http\u0026quot;), new HttpHost(\\\u0026quot;localhost\\\u0026quot;, 9201, \\\u0026quot;http\\\u0026quot;)));  这里可以一次创建多个es的连接\n2、查询\n（1）get api\n//创建查询请求 GetRequest getRequest = new GetRequest(_index,_type,_id); //发起请求 GetResponse getResponse = client.get(getRequest); //请求结果,是否存在，存在就获取 if(getResponse.isExists()){ getResponse.getSourceAsString(); }  （2）search api\n//创建SearchSourceBuilder，设置请求体参数 SearchSourceBuilder sourceBuilder = new SearchSourceBuilder(); //设置分页 if(offset !=null \u0026amp;\u0026amp; limit != null){ sourceBuilder.from(offset); sourceBuilder.size(limit); } //设置多条件 BoolQueryBuilder queryBuilder = QueryBuilders.boolQuery(); //这是and连接查询 queryBuilder.must(QueryBuilders.matchPhraseQuery(\u0026quot;name\u0026quot;,\u0026quot;bd\u0026quot;)); queryBuilder .must(QueryBuilders.matchPhraseQuery(\u0026quot;age\u0026quot;,\u0026quot;19\u0026quot;)); //范围查询，jdk8语法：LocalDateTime queryBuilder .must(QueryBuilders.rangeQuery(\u0026quot;createtime\u0026quot;).from(LocalDateTime.parse (startDate, DateTimeFormatter.ofPattern(\u0026quot;yyyy-MM-dd HH:mm:ss\u0026quot;))).includeLower(true)); queryBuilder .must(QueryBuilders.rangeQuery(\u0026quot;createtime\u0026quot;).to(LocalDateTime.parse (endDate, DateTimeFormatter.ofPattern(\u0026quot;yyyy-MM-dd HH:mm:ss\u0026quot;))).includeUpper(true)); sourceBuilder.query(queryBuilder); //设置查询超时时间 sourceBuilder.timeout(new TimeValue(30, TimeUnit.SECONDS)); //创建请求 //设置_index SearchRequest searchRequest = new SearchRequest(index); //设置_type if(!StringUtils.isEmpty(type)){ searchRequest.types(type); } //设置请求体参数 searchRequest.source(sourceBuilder); //发送请求 SearchResponse searchResponse = client.search(searchRequest);\\ SearchHits hits = searchResponse.getHits(); //获取总记录数 int totalHits = (int)hits.getTotalHits(); //获取内容 hit.getSourceAsString();  （3）还有更多API，请参考\nhttps://www.elastic.co/guide/en/elasticsearch/client/java-rest/current/java-rest-high.html\n","id":7,"section":"posts","summary":"1、初始化一个 RestHighLevelClien RestHighLevelClient client = new RestHighLevelClient( RestClient.builder( new HttpHost(\u0026quot;localhost\u0026quot;, 9200, \u0026quot;http\u0026quot;), new HttpHost(\\\u0026quot;localhost\\\u0026quot;, 9201, \\\u0026quot;http\\\u0026quot;))); 这里可以一次创建多个es的连接 2、查询 （1）get api //创建查询请求 GetRequest getRequest = new GetRequest(_index,_type,_id); //发起请求 GetResponse getResponse =","tags":["elk"],"title":"Elasticsearch Java Api","uri":"https://huayuye.github.io/blog/2021/12/elasticsearch-java-api/","year":"2021"},{"content":"前言 logstash grok\n内置patterns: http://grokdebug.herokuapp.com/patterns 测试patterns 工具： http://grokdebug.herokuapp.com/ \\ngrok plugin doc: https://www.elastic.co/guide/en/logstash/current/plugins-filters-grok.html\n1、利用内置的规则过滤 （1）官网示例\nlog 55.3.244.1 GET /index.html 15824 0.043 filter pattern:%{IP:client} %{WORD:method} %{URIPATHPARAM:request} %{NUMBER:bytes} %{NUMBER:duration}  （2）测试用例\nlog 127.0.0.1@2019-04-12 16:50:50@127.0.0.1/grok/test@get@{name:\u0026quot;test\u0026quot;,age:\u0026quot;20\u0026quot;} filter patterns:%{GREEDYDATA:IP}@%{GREEDYDATA:DATE}@%{GREEDYDATA:API}@%{GREEDYDATA:Method}@%{GREEDYDATA:REQUESTPARAM}  这个测试用例中，我们的日志格式中，严格要求使用@作为标识符来分隔，以便我们取多个值（即我们自己记录的日志内容中不能再出现@符号，否则会出现日志格式错误，收集不到日志） 结果：\n { \u0026quot;IP\u0026quot;: [ [ \u0026quot;127.0.0.1\u0026quot; ] ], \u0026quot;DATE\u0026quot;: [ [ \u0026quot;2019-04-12 16:50:50\u0026quot; ] ], \u0026quot;API\u0026quot;: [ [ \u0026quot;127.0.0.1/grok/test\u0026quot; ] ], \u0026quot;Method\u0026quot;: [ [ \u0026quot;get\u0026quot; ] ], \u0026quot;REQUESTPARAM\u0026quot;: [ [ \u0026quot;{name:\u0026quot;test\u0026quot;,age:\u0026quot;20\u0026quot;}\u0026quot; ] ] }  注意： （1）官网的示例中，%前有一个空格，这是因为log中的内容是以空格来分隔（以什么分隔，可自己定义，如测试用例）。\n（2）测试用例中，%前有一个@，这是因为log中的内容是以空格来分隔 匹配规则：如 %{IP:client} 匹配的是第一个空格前的内容，获取其中符合ip格式的ip内容\n2、customer patterns (1)\nlog BEF25A72965fdf patterns : (?\u0026lt;queue_id\u0026gt;[0-9A-F]{10,11})  结果：\n\t{ \u0026quot;queue_id\u0026quot;: [ [ \u0026quot;BEF25A72965\u0026quot; ] ] }  注：queue_id:匹配完后，用于显示的key（可自己定义），但是这个方式，如果多个连起来的话，我是不知道怎么连，也没有测试成功的，有测试成功的朋友请赐教。\n（2）可以将 pattern 写在一个文件中(文件名自定义：https://www.elastic.co/guide/en/logstash/current/plugins-filters-grok.html)\na、可参考官网示例：https://www.elastic.co/guide/en/logstash/current/plugins-filters-grok.html\nb、测试用例 文件内容：TEST .*\nlog = 127.0.0.1@2019-04-12 16:50:50@127.0.0.1/grok/test@get@{name:\u0026quot;test\u0026quot;,age:\u0026quot;20\u0026quot;}  使用：\nfilter { grok { patterns_dir =\u0026gt; [\u0026quot;./patterns\u0026quot;] match =\u0026gt; { \u0026quot;message\u0026quot; =\u0026gt; \u0026quot;%{TEST:IP}@%{GREEDYDATA:DATE}@%{GREEDYDATA:API}@%{GREEDYDATA:Method}@%{GREEDYDATA:REQUESTPARAM}\u0026quot; } } }  （3）也可以将patterns写在filter 中\n filter { grok { match =\u0026gt; { \u0026quot;message\u0026quot; =\u0026gt; \u0026quot;%{TEST:IP}@%{GREEDYDATA:DATE}@%{GREEDYDATA:API}@%{GREEDYDATA:Method}@%{GREEDYDATA:REQUESTPARAM}\u0026quot; } pattern_definitions =\u0026gt; { \u0026quot;TEST\u0026quot; =\u0026gt; \u0026quot;.*\u0026quot; # 使用键值对方式 } } }  3、其他的方式 更深入只能朋友自己去研究了，这里面的配置很庞大，很强大\n","id":8,"section":"posts","summary":"前言 logstash grok 内置patterns: http://grokdebug.herokuapp.com/patterns 测试patterns 工具： http://grokdebug.herokuapp.com/ \\ngrok plugin doc: https://www.elastic.co/guide/en/logstash/current/plugins-filters-grok.html 1、利用内置的规则过滤 （1）官网示例 log 55.3.244.1 GET /index.html 15824 0.043 filter pattern:%{IP:client} %{WORD:method} %{URIPATHPARAM:request} %{NUMBER:bytes} %{NUMBER:duration} （2）测试用","tags":["elk"],"title":"Logstash Grok","uri":"https://huayuye.github.io/blog/2021/12/logstash-grok/","year":"2021"},{"content":"准备 下载相应的安装包：https://www.elastic.co/downloads，我这里用的5.6.3版本的。\nLogstash：日志收集\nElasticSearch：日志存储与搜索\nKibana：日志展示\nJDK8\n安装 logstash (1) wget https://www.elastic.co/downloads/logstash/logstash-5.6.3.tar.gz\n解压后是没有logstash的配置文件的，需要手动在解压包下（/home/bingdeng/javaDev/elk/logstash5.6.3）创建一个logstash.conf，为了测试，只是配置了简单的标准输入和标准输出及从文件读取日志，内容如下：\ninput{ #标准输入读取 stdin{} #从文件读取内容 file { path =\u0026gt; \u0026quot;/home/bingdeng/elk/log/*.log\u0026quot; #从文件开始处读取 start_position =\u0026gt; \u0026quot;beginning\u0026quot; } } #过滤指定格式的日志 filter { #测试日志格式实例 ： 55.3.244.1 GET /index.html 15824 0.043 #定义数据的格式,字段内容以空格区分： grok { match =\u0026gt; {\u0026quot;message\u0026quot;=\u0026gt;\u0026quot;%{IP:client} %{WORD:method} %{URIPATHPARAM:request} %{NUMBER:bytes} %{NUMBER:duration}\u0026quot;} } #（如IP 由grok_patterns提供(格式：%{IP:client} ) ，client 自己定义，表示解析后的字段名） [https://github.com/logstash-plugins/logstash-patterns-core/blob/master/patterns/grok-patterns](https://github.com/logstash-plugins/logstash-patterns-core/blob/master/patterns/grok-patterns) #输出结果 #{ #\u0026quot;duration\u0026quot; =\u0026gt; \u0026quot;0.043\u0026quot;, # \u0026quot;request\u0026quot; =\u0026gt; \u0026quot;/index.html\u0026quot;, # \u0026quot;@timestamp\u0026quot; =\u0026gt; 2018-05-28T05:52:16.734Z, # \u0026quot;method\u0026quot; =\u0026gt; \u0026quot;GET\u0026quot;, # \u0026quot;bytes\u0026quot; =\u0026gt; \u0026quot;15824\u0026quot;, # \u0026quot;@version\u0026quot; =\u0026gt; \u0026quot;1\u0026quot;, # \u0026quot;host\u0026quot; =\u0026gt; \u0026quot;bingdengfh\u0026quot;, # \u0026quot;client\u0026quot; =\u0026gt; \u0026quot;55.3.244.1\u0026quot;, # \u0026quot;message\u0026quot; =\u0026gt; \u0026quot;55.3.244.1 GET /index.html 15824 0.043\u0026quot; #} #定义客户端的IP是哪个字段（上面定义的数据格式） # geoip { # source =\u0026gt; \u0026quot;client\u0026quot; #} } #输出 output{ #配置elasticsearch的服务器路径及端口 elasticsearch{ hosts =\u0026gt; \u0026quot;192.168.43.100:9201\u0026quot; #索引：可动态设置 index =\u0026gt; \u0026quot;logstash-test\u0026quot; } stdout{ codec =\u0026gt;rubydebug{} } }  （2）、 在logstash的解压目录下执行命令：./bin/logstash -f logstash.conf，启动logstash\n成功：\n安装elasticsearch (1)wget https://www.elastic.co/downloads/elasticsearch/elasticsearch-5.6.3.tar.gz\n进入到elasticsearch的安装目录的config下，修改配置： vi elasticsearch.yml\npath.data修改为自己本机的data路径，自定义(这个路径如果不存在的话需要手动去创建)\npath,logs修改为自己本机的logs路径，也是自定义吧（这个路径如果不存在的话，启动elasticsearch会自动创建）\nnetwork.host修改为安装服务器地址\nhttp.port为http访问端口，默认是9200，我这里给的9201\n内容如下：\n#======================== Elasticsearch Configuration ========================= # #NOTE: Elasticsearch comes with reasonable defaults for most settings. # Before you set out to tweak and tune the configuration, make sure you # understand what are you trying to accomplish and the consequences. #The primary way of configuring a node is via this file. This template lists #the most important settings you may want to configure for a production cluster. #Please consult the documentation for further information on configuration options: https://www.elastic.co/guide/en/elasticsearch/reference/index.html #---------------------------------- Cluster ----------------------------------- #Use a descriptive name for your cluster: #集群名称 cluster.name: es-test # #------------------------------------ Node ------------------------------------ #Use a descriptive name for the node: #集群节点名称 node.name: node-test-1 #Add custom attributes to the node: #node.attr.rack: r1 #----------------------------------- Paths ------------------------------------ #Path to directory where to store the data (separate multiple locations by comma): #path.data: /path/to/data path.data: /home/bingdeng/javaDev/elk/es-path/datas/ #Path to log files: #path.logs: /path/to/logs path.logs: /home/bingdeng/javaDev/elk/es-path/logs/ #----------------------------------- Memory ----------------------------------- #Lock the memory on startup: #bootstrap.memory_lock: true #Make sure that the heap size is set to about half the memory available #on the system and that the owner of the process is allowed to use this #limit. #Elasticsearch performs poorly when the system is swapping the memory. #---------------------------------- Network ----------------------------------- #Set the bind address to a specific IP (IPv4 or IPv6): #network.host: 192.168.0.1 network.host: 192.168.43.100 #Set a custom port for HTTP: #http.port: 9200 http.port: 9201 #For more information, consult the network module documentation. #--------------------------------- Discovery ---------------------------------- #Pass an initial list of hosts to perform discovery when new node is started: #The default list of hosts is [\u0026quot;127.0.0.1\u0026quot;, \u0026quot;[::1]\u0026quot;] #discovery.zen.ping.unicast.hosts: [\u0026quot;host1\u0026quot;, \u0026quot;host2\u0026quot;] #Prevent the \u0026quot;split brain\u0026quot; by configuring the majority of nodes (total number of master-eligible nodes / 2 + 1): #discovery.zen.minimum_master_nodes: 3 #For more information, consult the zen discovery module documentation. #---------------------------------- Gateway ----------------------------------- #Block initial recovery after a full cluster restart until N nodes are started: #gateway.recover_after_nodes: 3 #For more information, consult the gateway module documentation. #---------------------------------- Various ----------------------------------- #Require explicit names when deleting indices: #action.destructive_requires_name: true  (2)到elasticsearch目录下执行 ./bin/elasticsearch，启动elasticsearch\n访问 http://192.168.43.100:9201/\n页面出现：\n{\n\u0026ldquo;name\u0026rdquo; : \u0026ldquo;node-test-1\u0026rdquo;,\n\u0026ldquo;cluster_name\u0026rdquo; : \u0026ldquo;es-test\u0026rdquo;,\n\u0026ldquo;cluster_uuid\u0026rdquo; : \u0026ldquo;yuxNWTZcRpyNOnLvS2j0kQ\u0026rdquo;,\n\u0026ldquo;version\u0026rdquo; : {\n\u0026ldquo;number\u0026rdquo; : \u0026ldquo;5.6.3\u0026rdquo;,\n\u0026ldquo;build_hash\u0026rdquo; : \u0026ldquo;1a2f265\u0026rdquo;,\n\u0026ldquo;build_date\u0026rdquo; : \u0026ldquo;2017-10-06T20:33:39.012Z\u0026rdquo;,\n\u0026ldquo;build_snapshot\u0026rdquo; : false,\n\u0026ldquo;lucene_version\u0026rdquo; : \u0026ldquo;6.6.1\u0026rdquo;\n},\n\u0026ldquo;tagline\u0026rdquo; : \u0026ldquo;You Know, for Search\u0026rdquo;\n}\n安装kibana (1)wget https://www.elastic.co/downloads/kibana/kibana-5.6.3-linux-x86_64.tar.gz\n进入kibana的解压目录的config目录下，编辑kibana.yml，server.port：5601放开，server.host修改为kibana的安装服务器，配置elasticsearch的路径端口\n内容如下：\n#Kibana is served by a back end server. This setting specifies the port to use. #server.port: 5601 server.port: 5601 #Specifies the address to which the Kibana server will bind. IP addresses and host names are both valid values. #The default is 'localhost', which usually means remote machines will not be able to connect. #To allow connections from remote users, set this parameter to a non-loopback address. #server.host: \u0026quot;localhost\u0026quot; #本kibana的服务器地址 server.host: \u0026quot;192.168.43.100\u0026quot; #Enables you to specify a path to mount Kibana at if you are running behind a proxy. This only affects #the URLs generated by Kibana, your proxy is expected to remove the basePath value before forwarding requests #to Kibana. This setting cannot end in a slash. #server.basePath: \u0026quot;\u0026quot; #The maximum payload size in bytes for incoming server requests. #server.maxPayloadBytes: 1048576 #The Kibana server's name. This is used for display purposes. #server.name: \u0026quot;your-hostname\u0026quot; #The URL of the Elasticsearch instance to use for all your queries. #elasticsearch.url: \u0026quot;http://localhost:9200\u0026quot; #elasticsearch的服务器地址及端口 elasticsearch.url: \u0026quot;http://192.168.43.100:9201\u0026quot; #When this setting's value is true Kibana uses the hostname specified in the server.host #setting. When the value of this setting is false, Kibana uses the hostname of the host #that connects to this Kibana instance. #elasticsearch.preserveHost: true #Kibana uses an index in Elasticsearch to store saved searches, visualizations and #dashboards. Kibana creates a new index if the index doesn't already exist. #kibana.index: \u0026quot;.kibana\u0026quot; #The default application to load. #kibana.defaultAppId: \u0026quot;discover\u0026quot; #If your Elasticsearch is protected with basic authentication, these settings provide #the username and password that the Kibana server uses to perform maintenance on the Kibana #index at startup. Your Kibana users still need to authenticate with Elasticsearch, which #is proxied through the Kibana server. #elasticsearch.username: \u0026quot;user\u0026quot; #elasticsearch.password: \u0026quot;pass\u0026quot; #Enables SSL and paths to the PEM-format SSL certificate and SSL key files, respectively. #These settings enable SSL for outgoing requests from the Kibana server to the browser. #server.ssl.enabled: false #server.ssl.certificate: /path/to/your/server.crt #server.ssl.key: /path/to/your/server.key #Optional settings that provide the paths to the PEM-format SSL certificate and key files. #These files validate that your Elasticsearch backend uses the same key files. #elasticsearch.ssl.certificate: /path/to/your/client.crt #elasticsearch.ssl.key: /path/to/your/client.key #Optional setting that enables you to specify a path to the PEM file for the certificate #authority for your Elasticsearch instance. #elasticsearch.ssl.certificateAuthorities: [ \u0026quot;/path/to/your/CA.pem\u0026quot; ] #To disregard the validity of SSL certificates, change this setting's value to 'none'. #elasticsearch.ssl.verificationMode: full #Time in milliseconds to wait for Elasticsearch to respond to pings. Defaults to the value of #the elasticsearch.requestTimeout setting. #elasticsearch.pingTimeout: 1500 #Time in milliseconds to wait for responses from the back end or Elasticsearch. This value #must be a positive integer. #elasticsearch.requestTimeout: 30000 #List of Kibana client-side headers to send to Elasticsearch. To send *no* client-side #headers, set this value to [] (an empty list). #elasticsearch.requestHeadersWhitelist: [ authorization ] #Header names and values that are sent to Elasticsearch. Any custom headers cannot be overwritten #by client-side headers, regardless of the elasticsearch.requestHeadersWhitelist configuration. #elasticsearch.customHeaders: {} #Time in milliseconds for Elasticsearch to wait for responses from shards. Set to 0 to disable. #elasticsearch.shardTimeout: 0 #Time in milliseconds to wait for Elasticsearch at Kibana startup before retrying. #elasticsearch.startupTimeout: 5000 #Specifies the path where Kibana creates the process ID file. #pid.file: /var/run/kibana.pid #Enables you specify a file where Kibana stores log output. #logging.dest: stdout #Set the value of this setting to true to suppress all logging output. #logging.silent: false #Set the value of this setting to true to suppress all logging output other than error messages. #logging.quiet: false #Set the value of this setting to true to log all events, including system usage information #and all requests. #logging.verbose: false #Set the interval in milliseconds to sample system and process performance #metrics. Minimum is 100ms. Defaults to 5000. #ops.interval: 5000 #The default locale. This locale can be used in certain circumstances to substitute any missing #translations. #i18n.defaultLocale: \u0026quot;en\u0026quot;  （2） 启动kibana，进入安装目录下： 执行 ./bin/kibana\n（3）访问 http://192.168.43.100:5601\n到此，elk安装及简单应用就完成了\n后期，会结合redis，或者使用filebeat\n","id":9,"section":"posts","summary":"准备 下载相应的安装包：https://www.elastic.co/downloads，我这里用的5.6.3版本的。 Logstash：日志收","tags":["elk"],"title":"Elk Install","uri":"https://huayuye.github.io/blog/2021/12/elk-install/","year":"2021"},{"content":"前言 jersey 框架：支持将文件上传到另一台的服务器上（tomcat为例））\n这里是直接使用tomcat搭建的一个文件服务器，搭建过程就不多蝉诉了\n代码 package com.bingdeng.demo.webapi.util; import cn.hutool.core.util.StrUtil; import cn.hutool.http.HttpUtil; import com.sun.jersey.api.client.Client; import com.sun.jersey.api.client.WebResource; import com.bingdeng.demo.webapi.handler.GlobalRunTimeException; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.springframework.web.multipart.MultipartFile; import javax.servlet.http.HttpServletResponse; import java.io.*; import java.net.ConnectException; import java.net.MalformedURLException; import java.net.URL; import java.text.SimpleDateFormat; import java.time.LocalDateTime; import java.util.Date; import java.util.UUID; import java.util.regex.Matcher; import java.util.regex.Pattern; /** * 文件操作工具类 * Created by fh on 2018/1/11. */ public class FileUtil { private static Logger log = LoggerFactory.getLogger(FileUtil.class); //校验路径开头 private static final String PATTERN_REGEX = \u0026quot;^(http|https)://.+\u0026quot;; //文件上传服务器 private static String fileHost; public static void setFileHost(String fileHost) { FileUtil.fileHost = fileHost; } /** * 存储文件 * * @param file 文件 * @param path 文件存储路径（文件夹） * @return */ public static String getUploadFileName(MultipartFile file, String path) { if (path == null) { log.error(\u0026quot;保存文件路径为空\u0026quot;); return null; } String newFileUrl = null; if (file != null) { //获取内容类型 // String contentType = file.getContentType(); //获取文件名及类型 String fieldOriginalName = file.getOriginalFilename(); //获取文件后缀 String fieldType = fieldOriginalName.substring(fieldOriginalName.lastIndexOf(\u0026quot;.\u0026quot;) + 1); //重新定义文件名 String tempNewName = getRandomFileName(); //保存图片服务器的请求路径 newFileUrl = path + tempNewName + \u0026quot;.\u0026quot; + fieldType; // long size = file.getSize(); try { //若是文件服务器，走这里 if (verifyUrlByRegEx(path)) { //实例化一个Jersey Client client = new Client(); //设置请求路径 WebResource resource = client.resource(newFileUrl); //发送post get put resource.put(String.class, file.getBytes()); } else { File dirPath = new File(path); if (!dirPath.exists()) { dirPath.mkdirs(); } dirPath.setWritable(true, false); file.transferTo(new File(newFileUrl)); File fieldIsExit = new File(newFileUrl); if (!fieldIsExit.exists()) { log.error(\u0026quot;文件转存失败\u0026quot;); } else { log.info(\u0026quot;文件上传成功：url={}\u0026quot;, newFileUrl); } newFileUrl = newFileUrl.replace(fileHost, \u0026quot;\u0026quot;); } } catch (IOException e) { log.error(\u0026quot;文件上传失败，msg:{}\u0026quot;, e.getMessage()); throw new GlobalRunTimeException(BondStatusCodeEnum.CODE_70004.getCode(), \u0026quot;文件上传失败\u0026quot;, null); } } return newFileUrl; } /** * 存储文件 * * @param fileBytes 文件 * @param nameSuffix 后缀名 * @param path 文件存储路径（文件夹） * @return */ public static String getUploadFileName(byte[] fileBytes, String path, String nameSuffix) { if (StrUtil.isEmpty(path) || StrUtil.isEmpty(nameSuffix)) { log.error(\u0026quot;文件路径或文件后缀名为空\u0026quot;); return null; } String newFileUrl = null; if (fileBytes != null \u0026amp;\u0026amp; fileBytes.length \u0026gt; 0) { //重新定义文件名-当前时间:如2018-6-9-10-30-57-104000000.jpg LocalDateTime today = LocalDateTime.now(); String tempNewName = getRandomFileName(); //保存图片服务器的请求路径 newFileUrl = path + tempNewName + \u0026quot;.\u0026quot; + nameSuffix; try { //若是文件服务器，走这里 if (verifyUrlByRegEx(path)) { //实例化一个Jersey Client client = new Client(); //设置请求路径 WebResource resource = client.resource(newFileUrl); //发送post get put resource.put(String.class, fileBytes); } else { File dirPath = new File(path); if (!dirPath.exists()) { dirPath.mkdirs(); } dirPath.setWritable(true, false); File fieldIsExit = cn.hutool.core.io.FileUtil.writeBytes(fileBytes, newFileUrl); if (!fieldIsExit.exists()) { log.error(\u0026quot;文件转存失败\u0026quot;); } else { log.info(\u0026quot;文件上传成功：url={}\u0026quot;, newFileUrl); } newFileUrl = newFileUrl.replace(fileHost, \u0026quot;\u0026quot;); } } catch (Exception e) { log.error(\u0026quot;文件上传失败，msg:{}\u0026quot;, e.getMessage()); throw new GlobalRunTimeException(BondStatusCodeEnum.CODE_70004.getCode(), \u0026quot;文件上传失败\u0026quot;, null); } } return newFileUrl; } /** * URL以http或者https开头返回true,否则返回false * * @param path * @return */ public static boolean verifyUrlByRegEx(String path) { Pattern pattern = Pattern.compile(PATTERN_REGEX); Matcher matcher = pattern.matcher(path); return matcher.matches(); } /** * 判断是否是支持的图片格式 * * @param type * @return */ public static boolean judgeImageType(String type) { for (String imageType : ConstantUtil.IMAGETYPE_CONSTANT) { if (imageType.equals(type.toLowerCase())) { return true; } } return false; } public static String getRandomFileName() { return UUID.randomUUID().toString().replace(\u0026quot;-\u0026quot;,\u0026quot;\u0026quot;); } }  ","id":10,"section":"posts","summary":"前言 jersey 框架：支持将文件上传到另一台的服务器上（tomcat为例）） 这里是直接使用tomcat搭建的一个文件服务器，搭建过程就不多蝉诉了 代码 package","tags":["文件操作"],"title":"Jersey","uri":"https://huayuye.github.io/blog/2021/12/jersey/","year":"2021"},{"content":"前言 之前一直想在nginx中配置网站使用https协议访问， 第一、https协议更加安全， 第二、自己也想学习配置一下。\n一、letsencrypt介绍及安装过程 1、letsencrypt官方地址 https://letsencrypt.org/\n2、下载脚本 git clone https://github.com/certbot/certbot.git\n3、安装命令 进入到certbot解压的文件夹\n./certbot-auto certonly --standalone --email xxxxx@qq.com -d xxx.com -d www.xxx.com -d xxx.xxx.com -d xxx.xxx.com  -d ：参数为你要生成证书的域名，支持一次性为多个域名生成\n​\t还有其它的安装方式，可参考官网上的 https://github.com/certbot/certbot.git\n4、证书生成位置\n/etc/letsencrypt/live/xxx.com/\n5、证书生成后，可如下配置nginx即可\nserver{ listen 443 ssl; server_name blog.lifefun.in; proxy_read_timeout 60; proxy_send_timeout 60; ssl_certificate /etc/letsencrypt/live/xxx.com/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/xxx.com/privkey.pem; access_log /root/xxx/solo.lifefun.com_access.log main; error_log /root/xxx/solo.lifefun.com_error.log; location / { proxy_pass xxx.xxxx.com; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $http_x_forwarded_for; client_max_body_size 100m; proxy_set_header REMOTE-HOST $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } }  二、过程中的trouble 我是在cent os 6.9上面安装的\n1、在执行安装命令的时候，提示certbot-auto 不存在\n解决方式：安装certbot-auto\n2、提示找不到依赖库\n可能我这里是因为yum源的问题，所以我这里的解决方式;替换为阿里的yum源\n步骤： (1)备份原来的：mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup\n(2) 下载:wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-6.repo\n(3) yum clean all，yum makecache 生成缓存\n三、certbot证书过期问题 由于certbot证书有个过期时间（90天），一般是到期前一个月才允许我们续期，因此我们需要手动更新或者脚本自动更新\n1、手动：重新执行一次命令 ./certbot-auto certonly --no-self-upgrade --standalone --email xxxxx@qq.com -d xxx.com -d www.xxx.com -d xxx.xxx.com -d xxx.xxx.com  2、定时：采用了linux自带的crontab,一般默认会自带 (1)我是直接执行 crontab -e\n在里面编辑，添加需要执行的任务：\n2 1 2 * * /root/xxxxxx/xxxxx/certbot-auto --no-self-upgrade renew --pre-hook \u0026quot;/root/nginx/xxxxxxxx/sbin/nginx -s stop\u0026quot; --post-hook \u0026quot;/root/nginx/xxxxxxxx/sbin/nginx -c /root/nginx/xxxxxxxxx/conf/nginx.conf\u0026quot; \u0026gt; /root/logs/xxxxxxxx/crontab-encrypt.log 2\u0026gt;\u0026amp;1 \u0026amp;  我这里是每月2号凌晨1点2分执行，并且将日志写入crontab-encrypt.log\n（2）也可以在/etc/crontab 里面编辑，添加（1）中的执行命令即可\n（3）必须记得重启定时服务\n重启：\nservice cronb restart #如果是centos7 版本， /bin/systemctl restart crond.service  启动：\nservice cronb start #如果是centos7 版本， /bin/systemctl start crond.service  停止：\nservice cronb stop #如果是centos7 版本， /bin/systemctl stop crond.service  （4）完成，到这里证书就会自动续期了\n四、期间问题： （1）没有启动定时服务，导致到点未执行 （2）没有记录日志，不知道是否执行成功 （3）必须先暂停nginx，然后执行更新命令，在重启nginx。（我这里碰到的问题是，执行更新时，端口nginx被占用）\n","id":11,"section":"posts","summary":"前言 之前一直想在nginx中配置网站使用https协议访问， 第一、https协议更加安全， 第二、自己也想学习配置一下。 一、letsencry","tags":["https"],"title":"Let Encrypt","uri":"https://huayuye.github.io/blog/2021/12/let-encrypt/","year":"2021"},{"content":"下面是我整理的常用 Git 命令清单。几个专用名词的译名如下。\n Workspace：工作区 Index / Stage：暂存区 Repository：仓库区（或本地仓库） Remote：远程仓库  一、新建代码库 # 在当前目录新建一个Git代码库 $ git init # 新建一个目录，将其初始化为Git代码库 $ git init [project-name] # 下载一个项目和它的整个代码历史 $ git clone [url]  二、配置 Git的设置文件为.gitconfig，它可以在用户主目录下（全局配置），也可以在项目目录下（项目配置）。\n# 显示当前的Git配置 $ git config --list # 编辑Git配置文件 $ git config -e [--global] # 设置提交代码时的用户信息 $ git config [--global] user.name \u0026quot;[name]\u0026quot; $ git config [--global] user.email \u0026quot;[email address]\u0026quot;  三、增加/删除文件 # 添加指定文件到暂存区 $ git add [file1] [file2] ... # 添加指定目录到暂存区，包括子目录 $ git add [dir] # 添加当前目录的所有文件到暂存区 $ git add . # 添加每个变化前，都会要求确认 # 对于同一个文件的多处变化，可以实现分次提交 $ git add -p # 删除工作区文件，并且将这次删除放入暂存区 $ git rm [file1] [file2] ... # 停止追踪指定文件，但该文件会保留在工作区 $ git rm --cached [file] # 改名文件，并且将这个改名放入暂存区 $ git mv [file-original] [file-renamed]  四、代码提交 # 提交暂存区到仓库区 $ git commit -m [message] # 提交暂存区的指定文件到仓库区 $ git commit [file1] [file2] ... -m [message] # 提交工作区自上次commit之后的变化，直接到仓库区 $ git commit -a # 提交时显示所有diff信息 $ git commit -v # 使用一次新的commit，替代上一次提交 # 如果代码没有任何新变化，则用来改写上一次commit的提交信息 $ git commit --amend -m [message] # 重做上一次commit，并包括指定文件的新变化 $ git commit --amend [file1] [file2] ...  五、分支 # 列出所有本地分支 $ git branch # 列出所有远程分支 $ git branch -r # 列出所有本地分支和远程分支 $ git branch -a # 新建一个分支，但依然停留在当前分支 $ git branch [branch-name] # 新建一个分支，并切换到该分支 $ git checkout -b [branch] # 新建一个分支，在远程分支上检出到本地分支，并切换到该分支 $ git checkout -b [branch] origin:[branch] # 以本地分支为基础，新建远程分支 $ git push origin [branch]:[remote] # 新建一个分支，指向指定commit $ git branch [branch] [commit] # 新建一个分支，与指定的远程分支建立追踪关系 $ git branch --track [branch] [remote-branch] # 切换到指定分支，并更新工作区 $ git checkout [branch-name] # 切换到上一个分支 $ git checkout - # 建立追踪关系，在现有分支与指定的远程分支之间 $ git branch --set-upstream [branch] [remote-branch] # 合并指定分支到当前分支 $ git merge [branch] # 选择一个commit，合并进当前分支 $ git cherry-pick [commit] # 删除分支 $ git branch -d [branch-name] # 删除远程分支 $ git push origin --delete [branch-name] $ git branch -dr [remote/branch]  六、标签 # 列出所有tag $ git tag # 新建一个tag在当前commit $ git tag [tag] # 新建一个tag在指定commit $ git tag [tag] [commit] # 删除本地tag $ git tag -d [tag] # 删除远程tag $ git push origin :refs/tags/[tagName] # 查看tag信息 $ git show [tag] # 提交指定tag $ git push [remote] [tag] # 提交所有tag $ git push [remote] --tags # 新建一个分支，指向某个tag $ git checkout -b [branch] [tag]  七、查看信息 # 显示有变更的文件 $ git status # 显示当前分支的版本历史 $ git log # 显示commit历史，以及每次commit发生变更的文件 $ git log --stat # 搜索提交历史，根据关键词 $ git log -S [keyword] # 显示某个commit之后的所有变动，每个commit占据一行 $ git log [tag] HEAD --pretty=format:%s # 显示某个commit之后的所有变动，其\u0026quot;提交说明\u0026quot;必须符合搜索条件 $ git log [tag] HEAD --grep feature # 显示某个文件的版本历史，包括文件改名 $ git log --follow [file] $ git whatchanged [file] # 显示指定文件相关的每一次diff $ git log -p [file] # 显示过去5次提交 $ git log -5 --pretty --oneline # 显示所有提交过的用户，按提交次数排序 $ git shortlog -sn # 显示指定文件是什么人在什么时间修改过 $ git blame [file] # 显示暂存区和工作区的差异 $ git diff # 显示暂存区和上一个commit的差异 $ git diff --cached [file] # 显示工作区与当前分支最新commit之间的差异 $ git diff HEAD # 显示两次提交之间的差异 $ git diff [first-branch]...[second-branch] # 显示今天你写了多少行代码 $ git diff --shortstat \u0026quot;@{0 day ago}\u0026quot; # 显示某次提交的元数据和内容变化 $ git show [commit] # 显示某次提交发生变化的文件 $ git show --name-only [commit] # 显示某次提交时，某个文件的内容 $ git show [commit]:[filename] # 显示当前分支的最近几次提交 $ git reflog  八、远程同步 # 下载远程仓库的所有变动 $ git fetch [remote] # 显示所有远程仓库 $ git remote -v # 显示某个远程仓库的信息 $ git remote show [remote] # 增加一个新的远程仓库，并命名 $ git remote add [shortname] [url]\\ # 取回远程仓库的变化，并与本地分支合并 $ git pull [remote] [branch] # 上传本地指定分支到远程仓库 $ git push [remote] [branch] # 强行推送当前分支到远程仓库，即使有冲突 $ git push [remote] --force # 推送所有分支到远程仓库 $ git push [remote] --all # 以本地分支为基础，新建并推送到远程分支 $ git push origin [branch]  九、撤销 # 恢复暂存区的指定文件到工作区 $ git checkout [file] # 恢复某个commit的指定文件到暂存区和工作区 $ git checkout [commit] [file] # 恢复暂存区的所有文件到工作区 $ git checkout . # 重置暂存区的指定文件，与上一次commit保持一致，但工作区不变 $ git reset [file] # 重置暂存区与工作区，与上一次commit保持一致 $ git reset --hard # 重置当前分支的指针为指定commit，同时重置暂存区，但工作区不变 $ git reset [commit] # 重置当前分支的HEAD为指定commit，同时重置暂存区和工作区，与指定commit一致 $ git reset --hard [commit] # 重置当前HEAD为指定commit，但保持暂存区和工作区不变 $ git reset --keep [commit] # 新建一个commit，用来撤销指定commit # 后者的所有变化都将被前者抵消，并且应用到当前分支 $ git revert [commit] # 暂时将未提交的变化移除，稍后再移入 $ git stash $ git stash pop # 把readme.txt在工作区的修改全部撤销（未执行git add前） $ git checkout -- readme.txt # 把readme.txt暂存区的修改撤销，重新放回工作区（即执行 git add 后） $ git reset HEAD readme.txt #示例：若是git add 后,想撤销到工作区，可以执行此条命条，再执行上条命令即可 # 版本回滚 # 从近到远查看提交日志 $ git log # 回退到上一个版本，^^两个箭头就表示上上个版本，依次类推 $ git reset --hard HEAD^ # 回退到指定版本号 $ git reset --hard 3628164 # 查看最近几次提交记录的版本号（可以用于查询寻找相应的版本号，用于回滚） $ git reflog  十、其他 # 生成一个可供发布的压缩包 $ git archive  以上转载于：http://www.ruanyifeng.com/blog/2015/12/git-cheat-sheet.html\n下面说说我的首个代码上传github的流程 1、在用户目录下或项目目录下执行（自己喜欢,我是在这目录下：/c/Users/Administrator），这是设置提交人的信息\nbingdeng@bingdeng MINGW64 ~ $ git config --global user.name \u0026quot;xxxxxx\u0026quot; bingdeng@bingdeng MINGW64 ~ $ git config --global user.email \u0026quot;xxxxx@qq.com\u0026quot;  2、没有ssh key则按以下方式生成, -C 后面加github注册邮箱,成功的话会在此目录下生成一个.ssh文件夹，里面包含两个文件\nbingdeng@bingdeng MINGW64 ~ $ ssh-keygen -t rsa -C \u0026quot;xxxxx@qq.com\u0026quot; bingdeng@bingdeng MINGW64 ~ $ pwd /c/Users/Administrator bingdeng@bingdeng MINGW64 ~ $ cd .ssh/ bingdeng@bingdeng MINGW64 ~/.ssh $ ls id_rsa id_rsa.pub  3、将id_rsa.pub中的密钥用于配置github中的ssh key github配置ssh key,登录github，右上角的账户信息区域，选择settings-左菜单选中ssh and GPG keys -右边内容点击New SSH key -输入你的tilte(建议与库名称一致)和key(id_rsa.pub中的内容) - Add SSH key 即可完成配置\n4、初始化git (进入到项目目录（/f/ideaWorkspace/projectSpace/my-site）执行命令)\nbingdeng@bingdeng MINGW64 /f/ideaWorkspace/projectSpace/my-site $ git init Initialized empty Git repository in F:/ideaWorkspace/projectSpace/my-site/.git/  5、新增远程仓库并命名为origin(关联github库)\nbingdeng@bingdeng MINGW64 /f/ideaWorkspace/projectSpace/my-site (master) $ git remote add origin https://github.com/huayuye/my-site.git  6、拉取远程最新代码\nbingdeng@bingdeng MINGW64 /f/ideaWorkspace/projectSpace/my-site (master) $git pull origin master  7、将该目录下的所有文件上传到缓冲区\nbingdeng@bingdeng MINGW64 /f/ideaWorkspace/projectSpace/my-site (master) $ git add .  8、提交到仓库\nbingdeng@bingdeng MINGW64 /f/ideaWorkspace/projectSpace/my-site (master) git commit -m \u0026quot;提交时的说明\u0026quot;  9、上传本地指定分支到远程仓库,执行到此步骤的时候，我的第一次提示错误，我再执行一次，提示输入用户名密码，输入github用户名和密码即可,如果提交失败，可以添加参数 -force\nbingdeng@bingdeng MINGW64 /f/ideaWorkspace/projectSpace/my-site (master) $ git push origin master  至此大功告成，去github上查看，就有你上传的项目了\n","id":12,"section":"posts","summary":"下面是我整理的常用 Git 命令清单。几个专用名词的译名如下。 Workspace：工作区 Index / Stage：暂存区 Repository：仓库区（或本地仓","tags":["git"],"title":"Git Command","uri":"https://huayuye.github.io/blog/2021/12/git-command/","year":"2021"},{"content":"前言\n今天使用nginx做负载，在上传图片时，一直报500错误（Internal Server Error 500）， 开始已为是程序问题，但是在本地上传是没有问题的。 所以就往nginx的配置方面想了\n一、原来的配置  #user root; worker_processes 1; worker_rlimit_nofile 102400; events { worker_connections 65535; use epoll; multi_accept on; } http { include mime.types; default_type application/octet-stream; log_format main '[$content_type]--[$remote_addr] -$remote_user [$time_local] \u0026quot;[$request]\u0026quot; ' '[$status] $body_bytes_sent [$request_body] \u0026quot;$http_referer\u0026quot; ' '\u0026quot;$http_user_agent\u0026quot; \u0026quot;$http_x_forwarded_for\u0026quot;'; sendfile on; tcp_nopush on; server_names_hash_bucket_size 128; client_header_buffer_size 32k; large_client_header_buffers 4 32k; client_max_body_size 8m; fastcgi_connect_timeout 300; fastcgi_send_timeout 300; fastcgi_read_timeout 300; fastcgi_buffer_size 64k; fastcgi_buffers 4 64k; fastcgi_busy_buffers_size 128k; fastcgi_temp_file_write_size 128k; fastcgi_intercept_errors on; proxy_headers_hash_max_size 51200; proxy_headers_hash_bucket_size 6400; proxy_buffer_size 128k; proxy_buffers 32 128k; proxy_busy_buffers_size 128k; #keepalive_timeout 0; keepalive_timeout 10; tcp_nodelay on; server_tokens off; gzip on; gzip_min_length 1k; gzip_buffers 4 16k; gzip_http_version 1.0; gzip_comp_level 2; gzip_types text/plain application/x-javascript text/css application/xml application/json text/json text/xml; gzip_vary on; #sendfile on; #tcp_nopush on; #keepalive_timeout 0; #keepalive_timeout 65; #gzip on; #Load config files from the /etc/nginx/conf.d directory #The default server is in conf.d/default.conf include /root/nginx/conf.d/*.conf; }  二、解决方案 1、方案一\n（1）在/etc/security/limits.conf 添加配置\n soft nofile 65535 hard nofile 65535  （2）在nginx中配置\nworker_rlimit_nofile 65535\n（我原配置也有配）, 结果没有用\n2、方案二\n（1）在nginx上配置\nclient_body_buffer_size #使用默认设置，8k或者16k client_header_buffer_size #设置得比较大  我的原配置也有配置,这也没解决我的问题\n3、方案三\n修改nginx中user,我这里修改为root，结果令我意外的是，居然可以上传了,至此解决了我得问题\n三、nginx 和 user 和 大小之间的关系 后续补上\n","id":13,"section":"posts","summary":"前言 今天使用nginx做负载，在上传图片时，一直报500错误（Internal Server Error 500）， 开始已为是程序问题，但是在本地上传是没有问题的。","tags":["nginx"],"title":"Nginx上传文件500","uri":"https://huayuye.github.io/blog/2021/11/nginx-file-500/","year":"2021"},{"content":"一、服务启动报错 ERROR com.rabbitmq.client.impl.ForgivingExceptionHandler - An unexpected connection driver error occured java.net.SocketException: socket closed  二、根据错误显示，大概是MQ的问题： 1、开始以为是 Virtual Hosts / 下的用户没远程登录权限 结果设置还是没用\n2、后来一看发现这个 Virtual Hosts / 没启用，点击启用后 发现启动失败了\n error,{not_a_dets_file recovery.dets  3、失败的原因就是这个文件（recovery.dets）出问题了，直接删除，重启。\n文件之所以出错，应该是磁盘空间满了，而MQ服务又没退出，才导致了recovery.dets文件损坏。\nRabbitMQ从3.7.0版本开始所有的消息数据到放在msg_stores/vhosts目录下，每个vhost单独放在一个子目录，每个子目录以 (vhost名字+哈希值).vhost命名，每个vhost分开存储\nC:\\Users\\bingdeng\\AppData\\Roaming\\RabbitMQ\\db\\rabbit@bingdeng-mnesia\\msg_stores\\vhosts\\628WB79CIFDYO9LJI6DKMI09L\\recovery.dets  ","id":14,"section":"posts","summary":"一、服务启动报错 ERROR com.rabbitmq.client.impl.ForgivingExceptionHandler - An unexpected connection driver error occured java.net.SocketException: socket closed 二、根据错误显示，大概是MQ的问题： 1、开始以为是 Virtual Hosts / 下的用户没远程登录权限 结果设置还是没用 2、后","tags":["mq"],"title":"Mq Error, Recovery.Dets","uri":"https://huayuye.github.io/blog/2021/11/mq-recovery-dets/","year":"2021"},{"content":"注解\nJDK1.5版本才有的，理解为元数据，即描述数据的数据。 注解里面没有业务逻辑。\n理解 注解是元数据，描述数据的数据 注解不涉及逻辑处理，用户可以根据注解来实现相应的逻辑。 注解也可以理解为一个特殊的类 注解可以替代xml来定义相应的数据（如bean），使得更简洁，减少xml的配置\n一、java元注解 1、元注解\n@Documented –注解是否将包含在JavaDoc中\n@Retention –什么时候使用该注解\n@Target –注解用于什么地方（类/方法/包/域）\n@Inherited – 是否允许子类继承该注解\n2、元注解中的属性\n（1）@Documented\n一个简单的Annotations标记注解，表示是否\t将注解信息添加在java文档中。\n（2）@Retention 定义该注解的生命周期。\nRetentionPolicy.SOURCE – 在编译阶段丢弃。\n这些注解在编译结束之后就不再有任何意义，所以它们不会写入字节码。@Override, @SuppressWarnings都属于这类注解。\nRetentionPolicy.CLASS – 在类加载的时候丢弃。在字节码文件的处理中有用。注解默认使用这种方式。\nRetentionPolicy.RUNTIME– 始终不会丢弃，运行期也保留该注解，因此可以使用反射机制读取该注解的信息。我们自定义的注解通常使用这种方式。\n（3）@Target – 表示该注解用于什么地方。如果不明确指出，该注解可以放在任何地方。 以下是一些可用的参数。需要说明的是：属性的注解是兼容的，如果你想给7个属性都添加注解，仅仅排除一个属性，那么你需要在定义target包含所有的属性。\nElementType.TYPE:用于描述类、接口或enum声明\nElementType.FIELD:用于描述实例变量\nElementType.METHOD\nElementType.PARAMETER\nElementType.CONSTRUCTOR\nElementType.LOCAL_VARIABLE\nElementType.ANNOTATION_TYPE 另一个注释\nElementType.PACKAGE 用于记录java文件的package信息\n（4）@Inherited – 定义该注释和子类的关系\n二、自定义注解 像在平时定义接口类时，interface前添加一个@，就会使之成为一个注解\n注解的属性类型支持： 基本数据类型，String,enum\n\t//接口，类,枚举 @Target({ElementType.TYPE,ElementType.METHOD}) //运行时仍然有效 @Retention(RetentionPolicy.RUNTIME) public @interface MyAnnotation { //属性定义方式：类似定义一个接口方法，接口名即属性名，使用defult赋默认值 String value() default \u0026quot;myAnnotation\u0026quot;; }  三、解析注解 利用反射解析并获取其中的内容\npackage com.test.annotation; @MyAnnotation(\u0026quot;testMyAnnotation\u0026quot;) public class AnnotationTest { public static void main(String[] args) throws NoSuchMethodException { MyAnnotation myAnnotation = AnnotationTest.class.getAnnotation(MyAnnotation.class); System.out.println(\u0026quot;testMyAnnotation = \u0026quot;+myAnnotation.value()); MyAnnotation myAnnotation2 = AnnotationTest.class.getMethod(\u0026quot;testMyAnnotation\u0026quot;,String.class).getAnnotation(MyAnnotation.class); System.out.println(\\\u0026quot;testMyAnnotationMethon = \u0026quot;+myAnnotation2.value()); } @MyAnnotation(\u0026quot;testMyAnnotationMethon\u0026quot;) public void testMyAnnotation(String str) throws NoSuchMethodException { System.out.println(\u0026quot;testMyAnnotation = \u0026quot;+str); } }  ","id":15,"section":"posts","summary":"注解 JDK1.5版本才有的，理解为元数据，即描述数据的数据。 注解里面没有业务逻辑。 理解 注解是元数据，描述数据的数据 注解不涉及逻辑处理，用户可","tags":["java"],"title":"Java Meta Annotation","uri":"https://huayuye.github.io/blog/2021/11/java-meta-annotation/","year":"2021"},{"content":"1、 jps 列出已装载的JVM 请参考文档。\n2、 jstack 打印线程堆栈信息 请参考文档。\n3、jstat JVM监控统计信息，包括类的加载和卸载情况，新生代和老年代的容量、使用情况等信息。 -class -compiler -gc -gccapacity -gccause -gcnew -gcnewcapacity -gcold -gcoldcapacity -gcpermcapacity -gcutil -printcompilation 请参考文档。\n4、jmap 打印JVM堆内对象情况 请参考文档） -dump:[live,]format=b,file=\u0026lt; filename\u0026gt; 使用hprof二进制形式,输出jvm的heap内容到文件=. live子选项是可选的，假如指定live选项,那么只输出活的对象到文件。 -finalizerinfo 打印正等候回收的对象的信息。 -heap 打印heap的概要信息，GC使用的算法，heap的配置及wise heap的使用情况。 -histo[:live] 打印每个class的实例数目、内存占用、类全名信息。VM的内部类名字开头会加上前缀“”。如果live子参数加上后,只统计活的对象数量。\\n\\n -clstats 打印classload的信息。包含每个classloader的名字、活泼性、地址、父classloader和加载的class数量。 -F 在pid没有响应的时候强制使用-dump或者-histo参数。在这个模式下，live子参数无效。\n5、 jinfo jinfo可以输出并修改运行时的java 进程的opts。用处比较简单，用于输出JAVA系统参数及命令行参数。请参考文档。\n6、jconsole 一个java GUI监视工具，可以以图表化的形式显示各种数据。可通过远程连接监视远程的服务器VM。在cmd命令行里输入jconsole，选择进程就可以了。需要注意的就是在运行jconsole之前，必须要先设置环境变量DISPLAY，否则会报错误。 请参考文档。\n7、 jvisualvm jvisualvm同jconsole都是一个基于图形化界面的、可以查看本地及远程的JAVA GUI监控工具，Jvisualvm同jconsole的使用方式一样，直接在命令行打入Jvisualvm即可启动，不过Jvisualvm相比，界面更美观一些，数据更实时。请参考文档。\n8、jhat 用于对JAVA heap进行离线分析的工具，可以对不同虚拟机中导出的heap信息文件进行分析。请参考文档。\n9、jdb 用来对core文件和正在运行的Java进程进行实时地调试，里面包含了丰富的命令帮助您进行调试，它的功能和Sun studio里面所带的dbx非常相似，但jdb是专门用来针对Java应用程序的。现在应该说日常的开发中很少用到JDB了，因为现在的IDE已经帮我们封装好了，如使用ECLIPSE调用程序就是非常方便的，只要在非常特定的情况下可能会用到这个命令，如远程服务器的维护，没有IDE进行调试，那这个时候JDB应该可以帮上忙。请参考文档。\n10、jstatd jstatd是一个基于RMI（Remove Method Invocation）的服务程序，它用于监控基于HotSpot的JVM中资源的创建及销毁，并且提供了一个远程接口允许远程的监控工具连接到本地的JVM执行命令。 请参考文档。\n参考：http://blog.csdn.net/weitry/article/details/53284586\n","id":16,"section":"posts","summary":"1、 jps 列出已装载的JVM 请参考文档。 2、 jstack 打印线程堆栈信息 请参考文档。 3、jstat JVM监控统计信息，包括类的加载和卸载情况，新生代和老年","tags":["jdk"],"title":"Jdk Tool","uri":"https://huayuye.github.io/blog/2021/11/jdk-tool/","year":"2021"},{"content":"关于本人之前遇到的一个位运算问题，简单的作了下分析，如有错误，望指正。\n/** * 二进制 逢二进一 * 八进制 逢八进一 * 十进制 逢十进一 * 十六进制 逢十六进一 A(10) B(11) C(12) D(13) E(14) F(15) */ /** * 十进制 转 二进制 *将 十进制数 除以 2 ，取每次的余数 再将余数倒排 即为对应的二进制 */ /** * 十进制 转 八进制 * 将 十进制数 除以 8 ，取每次的余数 再将余数倒排 即为对应的八进制 */ /** * 十进制 转 十六进制 * 将 十进制数 除以 16 ，取每次的余数 再将余数倒排 即为对应的十六进制 */ /** * 二进制 转 十进制 * 将二进制的每个权重值 相加 即为十进制 * 如 1 0110-\u0026gt; 1*2^4+0*2^3+1*2^2+1*2^1+0*2^0 */ /** * 二进制 转 八进制 * 将二进制从右往左 每三位（权重值） 表示一位八进制数，不足时 空位补0 */ /** * 二进制 转 十六进制 * 将二进制从右往左 每四位（权重值） 表示一位十六进制数，不足时 空位补0 */ /** * 八进制 转 二进制 * 将每位八进制数 用三位二进制数（必须是三位，不足时，左边补0）表示 * 或将每位八进制数 除以2 取每次余数 再倒排 即为对应二进制数 */ /** * 八进制 转 十进制 * 将每位八进制数 按权重值 相加 即为对应的十进制 * 如 226 -\u0026gt; 2*8^2+2*8^1+6*8^0 */ /** * 八进制 转 十六进制 * 可借助 十进制 或者 二进制 过渡 */ /** * 十六进制 转 二进制 * 将每位十六进制数 用四位二进制数（必须是四位，不足时，左边补0）表示 * 或将每位十六进制数 除以2 取每次余数 再倒排 即为对应二进制数 * 96 -\u0026gt; 1001 0110 */ /** * 十六进制 转 十进制 * 将每位十六进制数 按权重值 相加 即为对应的十进制 * 如 96 -\u0026gt; 9*16^1+6*16^0 */ /** * 十六进制 转 八进制 * 可借助 十进制 或者 二进制 过渡 */ /** * * * 1byte = 8bit * char = 2byte * short = 2byte * int = 4byte * long = 8byte * */   public static void main(String[] args) { /** * byte 与 bit 结合位运算 获取 byte 中每一位bit 的表示情况 */ //1、接受字节流，获取每个字节中每一位的值（bit）: byte -\u0026gt; bite String str = \u0026quot;1234A\u0026quot;; // 49: 0011 0001 // 50: 0011 0010 // 0 0011 001 右移一位 // 00 0011 00 右移两位 // 000 0011 0 右移三位 // 0000 0011 右移四位 // 00000 001 右移五位 System.out.println(\u0026quot;bit -\u0026gt; byte = [\u0026quot; + Integer.parseInt(\u0026quot;00110010\u0026quot;,2) + \u0026quot;]\u0026quot;); for(byte b:str.getBytes()){ //取第一位的值 System.out.println(b+\u0026quot; \u0026amp; 1 = \u0026quot; + (b \u0026amp; 1)); //第二位 System.out.println(b+\u0026quot;\u0026gt;\u0026gt;1 \u0026amp; 1 = \u0026quot; + (b\u0026gt;\u0026gt;1 \u0026amp; 1) ); //第三位，以此类推 System.out.println(b+\u0026quot;\u0026gt;\u0026gt;2 \u0026amp; 1 = \u0026quot; + (b\u0026gt;\u0026gt;2 \u0026amp; 1) ); //第四位 System.out.println(b+\u0026quot;\u0026gt;\u0026gt;3 \u0026amp; 1 = \u0026quot; + (b\u0026gt;\u0026gt;3 \u0026amp; 1) ); //第五位 System.out.println(b+\u0026quot;\u0026gt;\u0026gt;4 \u0026amp; 1 = \u0026quot; + (b\u0026gt;\u0026gt;4 \u0026amp; 1)); //第六位 System.out.println(b+\u0026quot;\u0026gt;\u0026gt;5 \u0026amp; 1 = \u0026quot; + (b\u0026gt;\u0026gt;5 \u0026amp; 1)); //第七位 System.out.println(b+\u0026quot;\u0026gt;\u0026gt;6 \u0026amp; 1 = \u0026quot; + (b\u0026gt;\u0026gt;6 \u0026amp; 1)); //第八位 System.out.println(b+\u0026quot;\u0026gt;\u0026gt;7 \u0026amp; 1 = \u0026quot; + (b\u0026gt;\u0026gt;7 \u0026amp; 1)); } //2、bite -\u0026gt; byte,未考虑负数情况，主要以左起第一位区分：0正。负数时 结果=Integer.parseInt()-256 String[] bitArr = {\u0026quot;00110001\u0026quot;,\u0026quot;00110010\u0026quot;}; for(String bit : bitArr){ // bit -\u0026gt; byte System.out.println(bit+\u0026quot; -\u0026gt; byte = \u0026quot; + (byte)Integer.parseInt(bit,2));//2：说明要转换的bit是二进制，默认是十进制 //byte -\u0026gt; String System.out.println((byte)Integer.parseInt(bit,2)+\u0026quot;-\u0026gt;String = \u0026quot; + new String(new byte[]{(byte)Integer.parseInt(bit,2)}) ); } /** * 位 运算 * \u0026amp; | ^ ～ \u0026gt;\u0026gt; \u0026lt;\u0026lt; */ //1、异或：按位异或，不同得1，同得0 //两数交换:规则，两数异或后的结果再与其中一个数异或得到另一个数 int a=1,b=2; a = a^b; b = a^b; a = a^b; System.out.println(\u0026quot;a=1,b=2 -\u0026gt; a=\u0026quot;+a+\u0026quot;,b=\u0026quot;+b); //一个数与另一个数异或两次结果还是这个数 int a1=1,b1=2; System.out.println(\u0026quot;a1=1,b1=2;a1^b1^b1= -\u0026gt; \u0026quot;+(a1^b1^b1)); //2、\u0026amp; ：全为1得1，否则得0 //3、| ：有1则得1 //4、a\u0026gt;\u0026gt;n 左补n个0,缩小原来的2^n ,a = a/2^n int a4=16;//0001 0000 System.out.println(\u0026quot;a4\u0026gt;\u0026gt;2(0000 0100) = \u0026quot;+(a4\u0026gt;\u0026gt;2)); //5、a\u0026lt;\u0026lt;n 右补n个0，增大为原来的 2^n ,a = a*2^n int a5=2;//0000 0010 System.out.println(\u0026quot;a5\u0026lt;\u0026lt;2(0000 1000) = \u0026quot;+(a5\u0026lt;\u0026lt;2)); }  ","id":17,"section":"posts","summary":"关于本人之前遇到的一个位运算问题，简单的作了下分析，如有错误，望指正。 /** * 二进制 逢二进一 * 八进制 逢八进一 * 十进制 逢十进一 * 十六进制 逢十六进一","tags":["二进制"],"title":"Binary Convert(二进制之转换)","uri":"https://huayuye.github.io/blog/2021/11/binary-convert/","year":"2021"},{"content":"mybatis where 标签的一个小坑，被我踩下去了.\n为什么我会踩这个坑，只是因为我在模糊查询时，不想使用${},而使用另一个标签。\n标签的作用就是将 传过来的参数绑定到另一自定义的变量上去，然后方便使用 #{}获取\n问题 sql :\n\u0026lt;where\u0026gt; \u0026lt;if test=\u0026quot;keyword!=null\u0026quot;\u0026gt; \u0026lt;bind name=\u0026quot;likeKeyword\u0026quot; value=\u0026quot;keyword+'%'\u0026quot;\u0026gt;\u0026lt;/bind\u0026gt; and TaskNo like #{likeKeyword} \u0026lt;/if\u0026gt; \u0026lt;/where\u0026gt;  当keyword不为null,sql中并不会自动去掉第一个and,导致sql报错。\n原因 and 前面还有内容(甚至不能有注释)\n解决方案：\n1、\n\u0026lt;where\u0026gt; \u0026lt;if test=\u0026quot;keyword!=null\u0026quot;\u0026gt; and TaskNo like concat(#{keyword},'%') \u0026lt;/if\u0026gt; \u0026lt;/where\u0026gt;  2、\n\u0026lt;where\u0026gt; \u0026lt;trim prefixOverrides=\u0026quot;and\u0026quot;\u0026gt; \u0026lt;if test=\u0026quot;keyword!=null\u0026quot;\u0026gt; \u0026lt;bind name=\u0026quot;likeKeyword\u0026quot; value=\u0026quot;keyword+'%'\u0026quot;\u0026gt;\u0026lt;/bind\u0026gt; and TaskNo like #{likeKeyword} \u0026lt;/if\u0026gt; \u0026lt;/trim\u0026gt;\t\u0026lt;/where\u0026gt;  ","id":18,"section":"posts","summary":"mybatis where 标签的一个小坑，被我踩下去了. 为什么我会踩这个坑，只是因为我在模糊查询时，不想使用${},而使用另一个标签。 标签的作用就是将 传过来的参数","tags":["mybatis"],"title":"Mybatis Where的坑","uri":"https://huayuye.github.io/blog/2021/11/mybatis-where/","year":"2021"},{"content":"之前因为每次idea加载项目都初始化index等时，gradle一致提示内存空间不足，于是就对gradle进行了配置\n配置 1、需要在gradle安装目录（如D:\\gradle）下的.gradle文件夹创建文件gradle.properties(如果存在就不用新建了)\n2、在文件中添加以下内容即可(内存分配大小自己决定)\n#开启线程守护，第一次编译时开线程，之后就不会再开了 org.gradle.daemon=true #配置编译时的虚拟机大小 org.gradle.jvmargs=-Xmx2048m -XX:MaxPermSize=512m -XX:+HeapDumpOnOutOfMemoryError -Dfile.encoding=UTF-8 #开启并行编译，相当于多条线程再走 org.gradle.parallel=true #启用新的孵化模式 org.gradle.configureondemand=true  ","id":19,"section":"posts","summary":"之前因为每次idea加载项目都初始化index等时，gradle一致提示内存空间不足，于是就对gradle进行了配置 配置 1、需要在gradl","tags":["gradle"],"title":"Gradle Vm","uri":"https://huayuye.github.io/blog/2021/11/gradle-vm/","year":"2021"},{"content":"hello word !!!  编译 1、\n2、\n","id":20,"section":"posts","summary":"hello word !!! 编译 1、 2、","tags":null,"title":"Hello","uri":"https://huayuye.github.io/blog/2021/11/hello/","year":"2021"}],"tags":[{"title":"dubbo","uri":"https://huayuye.github.io/blog/tags/dubbo/"},{"title":"elk","uri":"https://huayuye.github.io/blog/tags/elk/"},{"title":"git","uri":"https://huayuye.github.io/blog/tags/git/"},{"title":"gradle","uri":"https://huayuye.github.io/blog/tags/gradle/"},{"title":"https","uri":"https://huayuye.github.io/blog/tags/https/"},{"title":"index","uri":"https://huayuye.github.io/blog/tags/index/"},{"title":"java","uri":"https://huayuye.github.io/blog/tags/java/"},{"title":"jdk","uri":"https://huayuye.github.io/blog/tags/jdk/"},{"title":"mq","uri":"https://huayuye.github.io/blog/tags/mq/"},{"title":"mybatis","uri":"https://huayuye.github.io/blog/tags/mybatis/"},{"title":"nginx","uri":"https://huayuye.github.io/blog/tags/nginx/"},{"title":"二进制","uri":"https://huayuye.github.io/blog/tags/%E4%BA%8C%E8%BF%9B%E5%88%B6/"},{"title":"文件操作","uri":"https://huayuye.github.io/blog/tags/%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C/"}]}